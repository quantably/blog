---
title: "The Unspoken Power of Expectation Setting for AI Leaders"
date: "2025-04-14"
draft: true
tags:
  - Leadership
# banner: ./image.jpg
---

Stop blaming the tech or data for failed AI projects. The real killer? Unmet expectations. 

My move into AI management quickly taught me a crucial lesson: expectation setting is a non-negotiable for project success. 

Unlike other areas of tech, the hype around AI creates a dangerously wide expectation gap. AI leaders who are able to navigate this gap are the ones best positioned to turn visions into tangible results.

## Why AI Creates Unprecedented Expectation Challenges?

AI, more than other tech fields, is prone to misaligned expectations. Several factors contribute:

First, its technical complexity. AI can obscure its true capabilities and limitations, especially the significant behind-the-scenes effort required. A common example of this is underestimating the time needed to prepare the data. When working with clients I have this entire phase absent from the project plan, highlighting the gap in understanding this foundational work. Consuming an AI model unfortunately hides the meticulous data groundwork it depends on.

Second, AI systems are often probabilistic. Unlike traditional deterministic software where 2+2 always equals 4; AI outputs can vary, depend on data distributions, and aren't always perfect. This probabilistic nature requires a different mindset for evaluation and acceptance.

Finally, the AI development lifecycle differs from traditional software engineering and requires adaptation. AI development is more experimental and iterative, involving less linear paths and a higher potential for setbacks. This uncertainty can clash with expectations set by more predictable software development cycles.

In this post I aim to introduce the 3 types of expectations that AI leaders have to navigate most commonly.

## The Three Layers of AI Expectation Setting
### Layer 1: Technical Reality Expectations

This layer represents misalignments on the technical capabilities of an AI model. A key challenge is ensuring stakeholders understand what the technology can realistically achieve, especially its limitations.

For instance, a particularly potent learning experience for me involved a client baffled by a model's inability to make accurate predictions on data fundamentally different from its training set. This misunderstanding of the model's operational boundaries – its inability to reliably extrapolate far beyond the data it learned from – wasn't just a technical detail; it put the entire project at risk.

Another example, would be people assessing the model based on a few cherry picked examples which ultimately doesn't reflect the actual efficiacy of the model.

To manage technical reality expectations effectively, the AI leader must act as both translator and educator. Proactively clarifying a model's true capabilities and limitations *before* development ensures misunderstandings don't derail the project later. 

Analogies are powerful tools for bridging the understanding gap, especially with non-technical stakeholders. For example, to explain why a model struggles with data vastly different from its training set (poor generalisation), you might compare it to a doctor trained exclusively in the UK needing additional context and training before effectively practicing in parts of Africa where prevalent diseases differ significantly.

### Layer 2: Process Expectations

The data-first paradigm and iterative development cycle

Example: Your experience with clients not understanding the sequence of AI development


Stakeholder involvement as domain experts, not just clients

Example: How you reframed client involvement in data exploration


Educational tools to build shared understanding

Example: Your one-pager approach for different aspects of AI



### Layer 3: Outcome Expectations

Defining success metrics appropriate for AI capabilities
Tailoring communication to different stakeholders

Example: Your approach to executives (business outcomes), technical teams (implementation details), and end users (product focus)


The ongoing nature of AI systems

Example: Your garden analogy for model maintenance and drift


## Conclusion

How mastering expectation setting elevates AI leadership
Practical first steps for improving expectation setting in your organization
Call to action: Invite readers to share their own expectation setting challenges and strategies


I think one of the most under discussed aspects of being a good AI leader is the art of expectation setting. Compared to other tech leadership roles, learning the art of expectation setting is hugely important both with internal and external stakeholders.

### The Expectation Gap

- Opening hook about the pattern behind AI project failures
- Brief explanation of the unique expectation challenges in AI
- Why this challenge is more acute in AI than other technical domains
- Thesis: Expectation setting is the hidden superpower of successful AI leaders

What is the number one reason for AI project failures? I have to be honest, the answer was not what I expected? Rather than insufficient data or a lack of technical skills, the real issue? The expectation gap.

AI introduces 



Ultimately, the reason why learning to set expectations is so important is because of the hype-cycle that accompanies the field of AI. 

The best way to illustrate the need for expectation setting is to look at examples where the expectations are most awry:

1. An underestimation on the needed to aquire/clean the relevent data required for an ML solution. 


### The art of setting expectations

When it comes to delivering AI solutions to customers, the art of expectation setting is about aligning their wants with realworld capabilities without bringing them crashing down to earth.