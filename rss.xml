<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Peter Wooldridge | Blog]]></title><description><![CDATA[Living and working in London, Peter Wooldridge explores topics in AI.]]></description><link>https://quantably.co</link><generator>GatsbyJS</generator><lastBuildDate>Mon, 16 Feb 2026 08:40:34 GMT</lastBuildDate><item><title><![CDATA[Stop Asking AI Questions. Make It Ask You.]]></title><description><![CDATA[Two things are happening as coding agents improve. First, the sheer volume and speed of AI-generated changes makes it hard to care about‚Ä¶]]></description><link>https://quantably.co/make-ai-ask-you/</link><guid isPermaLink="false">https://quantably.co/make-ai-ask-you/</guid><pubDate>Mon, 02 Feb 2026 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Two things are happening as coding agents improve. First, the sheer volume and speed of AI-generated changes makes it hard to care about each one individually. Second - and more concerning - my capacity for judgement feels like it&apos;s slowly eroding.&lt;/p&gt;
&lt;p&gt;The standard advice is clear:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;you should be able to explain any production code that&apos;s committed, even if it was written by an agent.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I know that. I just can&apos;t motivate myself to.&lt;/p&gt;
&lt;p&gt;It&apos;s hard to care as much about code I didn&apos;t write much of - especially when it&apos;s also far easier to generate than before.&lt;/p&gt;
&lt;p&gt;The feedback loop I&apos;m seeing play out looks as follows:&lt;/p&gt;
&lt;p&gt;AI provides code ‚Üí human feels relief (problem solved, uncertainty gone) ‚Üí outcome is acceptable ‚Üí questioning feels like unnecessary effort ‚Üí human defers more readily next time ‚Üí judgement atrophies&lt;/p&gt;
&lt;p&gt;Sure, I still have eureka moments where I catch something the AI missed. But those wins are trending down. Not hard down, but down.&lt;/p&gt;
&lt;p&gt;I think we need to be concerned with this, and it represents an overlooked risk in the extinction scenarios that dominate the AI safety discourse. What if the AI gets out of control, not because of its super human intelligence but because we simply stopped exercising our judgement over it. The riskiest part is that if this happens gradually enough we might not even notice.&lt;/p&gt;
&lt;h2&gt;This isn&apos;t just me&lt;/h2&gt;
&lt;p&gt;Humans in general have a tendency to over-rely on automated recommendations. It&apos;s called automation bias which can give rise to two types of errors:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Over-reliance on automated recommendations even when contradictory information exists&lt;/li&gt;
&lt;li&gt;Failing to act when the automation doesn&apos;t provide a recommendation&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Both of these apply to AI-assisted coding. We accept generated code even when our instincts suggest problems. We fail to act when AI doesn&apos;t flag something.&lt;/p&gt;
&lt;p&gt;The well cited example that showcases both of these errors was &lt;a href=&quot;https://en.wikipedia.org/wiki/Air_France_Flight_447&quot;&gt;Air France 447&lt;/a&gt; which crashed in 2009. The automation disengaged and the pilots, unaccustomed to flying manually at that altitude, were unable to recover.&lt;/p&gt;
&lt;h2&gt;The inversion&lt;/h2&gt;
&lt;p&gt;The idea came to me whilst using an LLM to interrogate a podcast transcript. I&apos;d ask follow-up questions to crystallise my understanding - but the verbosity made it hard to take in.&lt;/p&gt;
&lt;p&gt;So I tried something different. After my questions, I asked the AI to quiz me instead - identify gaps in my understanding. It worked remarkably well. Not just ingraining new ideas, but highlighting where I was still missing clarity.&lt;/p&gt;
&lt;p&gt;It turns out a research group already did this with students. &lt;a href=&quot;https://solve.mit.edu/solutions/90692&quot; target=&quot;_blank&quot;&gt;Socratic Mind&lt;/a&gt; had students use an LLM to learn, then get quizzed until the AI was satisfied they understood. More effort, but unsurprisingly, much better long-term recall.&lt;/p&gt;
&lt;h2&gt;Applying this to code&lt;/h2&gt;
&lt;p&gt;My next idea was whether the same approach could be applied to coding. A pre-commit hook seemed like the obvious mechanism, but that&apos;s awkward to wire up to an interactive LLM session. Instead, I built it as a Claude Code skill - when I&apos;m ready to commit, I invoke it, get quizzed, and it only commits if I pass.&lt;/p&gt;
&lt;p&gt;The obvious objection is that this adds friction. But friction already exists - it just shows up later, when something breaks and I realise I never understood why the code was shaped that way. The models being right more often makes this worse, not better. Success breeds complacency.&lt;/p&gt;
&lt;h2&gt;What makes a good question&lt;/h2&gt;
&lt;p&gt;The goal is to expose gaps between what code does and why it&apos;s shaped that way. A bad question can be answered by reading the code back - &quot;what does this function do?&quot; proves nothing. A good question forces engagement with trade-offs. &quot;Why a map here instead of a for loop?&quot; - I either thought about that or I didn&apos;t. No way to fake it.
The categories that matter:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The problem - Not just &quot;add rate limiting&quot; but why it&apos;s needed here, what it&apos;s protecting against&lt;/li&gt;
&lt;li&gt;The key decisions - Where were there choices? What drove them? This is where AI-generated code is most dangerous - choices were made, but not by you&lt;/li&gt;
&lt;li&gt;The boundaries - What this code handles and what it explicitly doesn&apos;t&lt;/li&gt;
&lt;li&gt;The failure behaviour - Not every edge case, but the general character. Silently? Loudly? Gracefully?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are also the things that matter for maintenance. Knowing what code does tells you what IS happening. Why it&apos;s shaped that way tells you what SHOULD be happening - which is how you spot when something&apos;s wrong.&lt;/p&gt;
&lt;h2&gt;The transition period&lt;/h2&gt;
&lt;p&gt;Right now, AI-generated code is good but not reliable enough for full autonomy. Despite the narrative that you describe requirements and watch it get built, SWEs are still required for anything non-trivial. Maybe a day comes where they&apos;re not - we don&apos;t require understanding of combustion engines to drive a car.
But we&apos;re not there yet. Humans are still legally and professionally responsible. Someone needs to understand when things go wrong. And AI explanations of AI-generated code may be just as unreliable as the code itself.
Things are moving quickly. But right now, maintaining judgement might be the difference between catching something wrong or missing it entirely.&lt;/p&gt;
&lt;h2&gt;Try it yourself&lt;/h2&gt;
&lt;p&gt;The skill works as a drop-in replacement for &lt;code class=&quot;language-text&quot;&gt;git commit -m&lt;/code&gt;, and scales questioning to the magnitude of the change - a one-line fix doesn&apos;t need five questions.&lt;/p&gt;
&lt;h3&gt;Step 1: Create the skill file&lt;/h3&gt;
&lt;p&gt;Create a file at .claude/skills/socratic-commit-review.md in your repo (or ~/.claude/skills/ for global use) and insert the skill from &lt;a href=&quot;https://gist.github.com/quantably/a96478ebd4791ba8b215171502e0776a&quot; target=&quot;_blank&quot;&gt;this gist&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Step 2: When you&apos;re ready to commit&lt;/h3&gt;
&lt;p&gt;Instead of git commit -m, run /socratic-commit-review. Claude asks questions about your changes, then marks you PROCEED or REFLECT. Proceed prompts for a commit message and commits. Reflect suggests areas where your understanding was shaky.&lt;/p&gt;
&lt;p&gt;Here&apos;s an example interaction on a health app I&apos;m working on:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/bf1c67c7da3a008a65ae5167a4f0e12d/f51c0/skill-example.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 44.30379746835443%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABYlAAAWJQFJUiTwAAABbElEQVR42kVSWXaDMAzkIi14AQNhSV8atrIHev8bTSUB6cc8SWNblkbyEhchiRkOodWIQoPIGvIPuMiKZT4053lo5S6/5dj//HjDK4scWZbDnYk5QexCxFEovqPH/FnM54T0/NgaBauVWCnAHJzXtS36vsc4DpinEePQC/r+BwOBbf/Tkd+/0XUt2rZB2zRomlr8uqpQFgW8LE2QJrFUwJWlCVVAVWmlYPQB9rUKDv/EVZ2lyozWcqYCH15+S5ClsWjhTm3YXuB2oujQVTiWwTkYG8L3A0oSnB8HR8vTOGLfN2zbS+zvvmOeJyzLLFjXReJ1XcV/vVa6u2FeFgzDgGmaSKKB7i74fjwoIQX8YCINF05EEI1IG9GHdKqeT9Ho4uqa+QodacdoKGb7VZbwbtQuT/SaakzgaXILWvnQpAvrJxqeEF7981fMrXv3IqPMOe60PjwUXh3eO6MvwQ/LnFheDxmKlviC6KgC/AFfQxC1msXZUgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Example interaction with the socratic commit review skill&quot;
        title=&quot;&quot;
        src=&quot;/static/bf1c67c7da3a008a65ae5167a4f0e12d/f058b/skill-example.png&quot;
        srcset=&quot;/static/bf1c67c7da3a008a65ae5167a4f0e12d/c26ae/skill-example.png 158w,
/static/bf1c67c7da3a008a65ae5167a4f0e12d/6bdcf/skill-example.png 315w,
/static/bf1c67c7da3a008a65ae5167a4f0e12d/f058b/skill-example.png 630w,
/static/bf1c67c7da3a008a65ae5167a4f0e12d/40601/skill-example.png 945w,
/static/bf1c67c7da3a008a65ae5167a4f0e12d/78612/skill-example.png 1260w,
/static/bf1c67c7da3a008a65ae5167a4f0e12d/f51c0/skill-example.png 2994w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;Closing Thoughts&lt;/h2&gt;
&lt;p&gt;Getting quizzed cements why something was implemented a certain way. More surprisingly, it surfaces bugs - mismatches between what I thought I&apos;d asked for and what the AI generated. Those only become visible when you&apos;re forced to explain the implementation back. Even when there are no bugs, thinking through the code surfaces simpler approaches I&apos;d have otherwise missed.&lt;/p&gt;
&lt;p&gt;The friction is the point.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[My Claude Code Productivity Stack]]></title><description><![CDATA[I used to sit at my laptop watching Claude Code work. Now I set tasks running and check in when needed.]]></description><link>https://quantably.co/claude-code-productivity-stack/</link><guid isPermaLink="false">https://quantably.co/claude-code-productivity-stack/</guid><pubDate>Mon, 19 Jan 2026 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I used to sit at my laptop watching Claude Code work. Now I set tasks running and check in when needed. &lt;!-- excerpt --&gt;&lt;/p&gt;
&lt;p&gt;If you&apos;re still babysitting every session, this post is for you.&lt;/p&gt;
&lt;h2&gt;The Shift&lt;/h2&gt;
&lt;p&gt;Coding agents got good. Claude Code can plan, execute, and iterate until objectives are met. It works for hours without supervision if you give it clear direction.&lt;/p&gt;
&lt;p&gt;My job now:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Define tasks with success criteria&lt;/li&gt;
&lt;li&gt;Spin up agents and point them at problems&lt;/li&gt;
&lt;li&gt;Review and merge their work&lt;/li&gt;
&lt;li&gt;Handle the parts that need human judgement&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&apos;s how I&apos;ve set things up.&lt;/p&gt;
&lt;h2&gt;The Framework&lt;/h2&gt;
&lt;p&gt;My setup breaks down into four areas:&lt;/p&gt;
&lt;div style=&quot;text-align: center&quot;&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/1e63369eba4d2716acd2ee3142c674b6/71c1d/framework.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 38.60759493670886%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAAsTAAALEwEAmpwYAAABU0lEQVR42nVQz0sCURDeP7CDh6CbdugQBCkInZKSIALT6Br0T3go8mZBVISUBoJZurg/dLX17du3v/ft9q2bIUEfH4+ZeTPzzYzAoygIw1+GnMc/iOL/ES0gOI5r2Xg8ZjkRDx67WuboafOslau1srXnjZOX9Upj72qn1MiXGgVw/2Y3X8911Te0EJhlM2b7fuB5fhyH9x1l7fChcNEGi5ftrfNO5vi6WN+uNEvV23L1rnzaPMjXsx3pNSmGJtjri73+cDrT0y6yosqyKknKnJBknSDQtLksaaKoTjQdZcx2MDqUHUJNgzIQI+iEGtQilMEgBsPv3DBBai4iFDZMC0yUXdf70sn7hzgQpfFkiv0RGYjy53DUH4xm+tzzfUSUsbbIkSGNs2JZXE1wPd9kNjUtNEyNpWsRw4QCXboYDTlpAjZNxsbFOefp6fkK/kSiJVbdb8tErpFcyfa8AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Framework: One task vs Many tasks, Synchronous vs Asynchronous&quot;
        title=&quot;&quot;
        src=&quot;/static/1e63369eba4d2716acd2ee3142c674b6/f058b/framework.png&quot;
        srcset=&quot;/static/1e63369eba4d2716acd2ee3142c674b6/c26ae/framework.png 158w,
/static/1e63369eba4d2716acd2ee3142c674b6/6bdcf/framework.png 315w,
/static/1e63369eba4d2716acd2ee3142c674b6/f058b/framework.png 630w,
/static/1e63369eba4d2716acd2ee3142c674b6/40601/framework.png 945w,
/static/1e63369eba4d2716acd2ee3142c674b6/78612/framework.png 1260w,
/static/1e63369eba4d2716acd2ee3142c674b6/71c1d/framework.png 1536w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Each solves a different problem. Together, they let me ship more while doing less manual coding.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;1. On-the-Go Development&lt;/h2&gt;
&lt;p&gt;With agents doing more autonomously, it often doesn&apos;t make sense to sit and wait for them to solve an issue. The idea isn&apos;t to be constantly working, but to check in and make key decisions from wherever you are, rather than being chained to a desk.&lt;/p&gt;
&lt;p&gt;The central tenet of this approach is shifting from developing on a local laptop to having a server as your centralised development environment. That way it can be accessed from multiple devices and configured to support low bandwidth environments.&lt;/p&gt;
&lt;p&gt;When I first tried this, I used SSH to connect to Claude on remote terminals - it worked great on WiFi. But switching to mobile internet meant dropped connections. The breakthrough was finding a stack that survives patchy connectivity - trains, planes, coffee shops - reconnecting automatically without losing state.&lt;/p&gt;
&lt;p&gt;My approach is largely derived from &lt;a href=&quot;https://granda.org/en/2026/01/02/claude-code-on-the-go/&quot; target=&quot;_blank&quot;&gt;Jorge Granda&apos;s excellent post&lt;/a&gt;, which details a secure, mobile-friendly Claude workflow.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The stack:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tailscale&lt;/strong&gt; - Private mesh VPN. Server invisible to the internet.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mosh&lt;/strong&gt; - Mobile shell. Survives WiFi ‚Üí 4G switches and patchy connections. Since Claude runs on the server, it always has good bandwidth - only text output comes back to your device.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tmux&lt;/strong&gt; - Terminal multiplexer. Sessions persist when disconnected. Stop on laptop, pick up on phone from exactly where you left off.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token builtin class-name&quot;&gt;alias&lt;/span&gt; &lt;span class=&quot;token assign-left variable&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;mosh user@100.x.x.x -- tmux new-session -A -D -s main&apos;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For the full setup guide (server config, security hardening, Tailscale setup), see Granda&apos;s post linked above.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;My mobile setup:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Termius&lt;/strong&gt; - My mobile terminal of choice. Supports mosh.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wispr Flow&lt;/strong&gt; - Voice transcription. I use this on desktop too, but it&apos;s especially useful on mobile where typing into a terminal is tedious. Dictate your prompt, paste, done.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Quirks:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Screen resolution&lt;/strong&gt; - When connecting from different devices, resolutions can clash. The &lt;code class=&quot;language-text&quot;&gt;-D&lt;/code&gt; flag solves this - it detaches other clients when you connect, so the terminal resizes to your current device.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scrolling&lt;/strong&gt; - On mobile, scrolling previous conversations can work weirdly. Use &lt;code class=&quot;language-text&quot;&gt;Ctrl-b [&lt;/code&gt; then pg up to scrollback through messages.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;2. Scheduled Jobs&lt;/h2&gt;
&lt;p&gt;Some tasks should happen regularly without me asking - code reviews, progress summaries, dependency audits. Of course you can schedule scripts with cron, but the point is I don&apos;t want to figure out cron syntax. More importantly, it&apos;s not just about running scripts - it&apos;s about chaining calls together and having Claude summarise results into something useful, then send it to Slack, email, or just a markdown file on the server.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When to use this:&lt;/strong&gt; Any task you want to run regularly. Check yesterday&apos;s commits for security issues. Write a daily progress summary from commit history. Run the full test suite every week.&lt;/p&gt;
&lt;p&gt;I use &lt;a href=&quot;https://github.com/jshchnz/claude-code-scheduler&quot; target=&quot;_blank&quot;&gt;claude-code-scheduler&lt;/a&gt; for this. It&apos;s a plugin that installs with two lines:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;/plugin marketplace &lt;span class=&quot;token function&quot;&gt;add&lt;/span&gt; jshchnz/claude-code-scheduler
/plugin &lt;span class=&quot;token function&quot;&gt;install&lt;/span&gt; scheduler&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then you just tell Claude what you want scheduled in natural language.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Daily code review (weekdays at 9am):&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Schedule every weekday at 9am: review commits from the last 24 hours, check for bugs, security issues, and missing error handling&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;Progress summary (daily at 6pm):&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Daily at 6pm: summarise today&apos;s commits and key decisions to ~/progress/$(date +%Y-%m-%d).md&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;Tech debt tracking (weekly):&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Every Monday at 10am: scan the codebase for TODO comments, deprecated dependencies, and functions over 100 lines. Write a tech debt report to ~/reports/tech-debt.md&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The scheduler uses crontab under the hood. Tasks run even when you&apos;re not there.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;3. Long-Running Tasks&lt;/h2&gt;
&lt;p&gt;Some tasks take hours but are well-defined: implementing a feature with tests, large refactors, TDD loops. In these cases I don&apos;t want to babysit. I want Claude to keep iterating until the objective is met - not pause for approval at every unit test or subtask. The goals are clear; it should just keep going until it&apos;s done.&lt;/p&gt;
&lt;p&gt;This isn&apos;t appropriate for everything, but it works well for &quot;turn the handle&quot; tasks that need iteration.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The solution:&lt;/strong&gt; The &lt;a href=&quot;https://awesomeclaude.ai/ralph-wiggum&quot; target=&quot;_blank&quot;&gt;Ralph Wiggum plugin&lt;/a&gt; - a persistent loop that keeps Claude working until completion.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;/ralph-loop:ralph-loop &lt;span class=&quot;token string&quot;&gt;&quot;implement user auth with tests&quot;&lt;/span&gt; --max-iterations &lt;span class=&quot;token number&quot;&gt;50&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Claude keeps iterating - write code, run tests, fix failures, repeat - until completion or the iteration cap.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Overnight feature implementation&lt;/li&gt;
&lt;li&gt;TDD loops (test ‚Üí implement ‚Üí refine)&lt;/li&gt;
&lt;li&gt;Large refactors with clear success criteria&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Stop it anytime with &lt;code class=&quot;language-text&quot;&gt;/ralph-loop:cancel-ralph&lt;/code&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;4. Parallel Agents&lt;/h2&gt;
&lt;p&gt;I have three features to ship. Traditional solo dev workflows suggest working on them sequentially. But with agents doing the implementation, why not run them in parallel?&lt;/p&gt;
&lt;p&gt;Git worktrees let each agent work on an isolated branch with its own working directory. Tmux windows let me switch between them instantly. One agent is adding auth, another is building the API, a third is writing tests - all running simultaneously without stepping on each other.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The solution:&lt;/strong&gt; Git worktrees + tmux windows.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# Create isolated worktrees&lt;/span&gt;
&lt;span class=&quot;token function&quot;&gt;git&lt;/span&gt; worktree &lt;span class=&quot;token function&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;..&lt;/span&gt;/feat-auth feature/auth
&lt;span class=&quot;token function&quot;&gt;git&lt;/span&gt; worktree &lt;span class=&quot;token function&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;..&lt;/span&gt;/feat-api feature/api

&lt;span class=&quot;token comment&quot;&gt;# Launch agents in separate tmux windows&lt;/span&gt;
Ctrl-b c              &lt;span class=&quot;token comment&quot;&gt;# new window&lt;/span&gt;
&lt;span class=&quot;token builtin class-name&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;..&lt;/span&gt;/feat-auth &lt;span class=&quot;token operator&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; claude

Ctrl-b c              &lt;span class=&quot;token comment&quot;&gt;# another window&lt;/span&gt;
&lt;span class=&quot;token builtin class-name&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;..&lt;/span&gt;/feat-api &lt;span class=&quot;token operator&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; claude

&lt;span class=&quot;token comment&quot;&gt;# Switch between them&lt;/span&gt;
Ctrl-b n    &lt;span class=&quot;token comment&quot;&gt;# next&lt;/span&gt;
Ctrl-b p    &lt;span class=&quot;token comment&quot;&gt;# previous&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Each agent has its own context, its own branch, its own working directory. They don&apos;t interfere with each other.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Security Note&lt;/h2&gt;
&lt;p&gt;Running Claude on a remote server is safer than running it locally. If something goes wrong, the damage is limited to one server - not your laptop with all your credentials and personal files.&lt;/p&gt;
&lt;p&gt;The servers are invisible to the public internet:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tailscale&lt;/strong&gt; - Private mesh network, no public IP&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;UFW&lt;/strong&gt; - Firewall allowing only Tailscale traffic&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;No exposed ports, no attack surface.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://granda.org/en/2026/01/02/claude-code-on-the-go/&quot; target=&quot;_blank&quot;&gt;Claude Code on the Go&lt;/a&gt; - Detailed mosh/tmux/Tailscale setup&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/jshchnz/claude-code-scheduler&quot; target=&quot;_blank&quot;&gt;claude-code-scheduler&lt;/a&gt; - Scheduling plugin&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://awesomeclaude.ai/ralph-wiggum&quot; target=&quot;_blank&quot;&gt;Ralph Wiggum&lt;/a&gt; - Long-running task loops&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://termius.com&quot; target=&quot;_blank&quot;&gt;Termius&lt;/a&gt; - Mobile terminal with mosh support&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://wispr.flow&quot; target=&quot;_blank&quot;&gt;Wispr Flow&lt;/a&gt; - Voice transcription for mobile&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Pick the quadrant that solves your biggest problem. For most, that&apos;s on-the-go development. The rest follows.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[The AI Empiricist: Why Experimentation Trumps Authority]]></title><description><![CDATA[A friend is helping run an AI course. Lately, she's been inundated with what essentially boils down to the same question: Which LLM model should I use?]]></description><link>https://quantably.co/empirical-ai/</link><guid isPermaLink="false">https://quantably.co/empirical-ai/</guid><pubDate>Wed, 11 Jun 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;A friend is helping run an AI course. Lately, she&apos;s been inundated with what essentially boils down to the same question:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Which LLM model should I use?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- excerpt --&gt;
&lt;p&gt;Different people, different projects but the same hunt for certainty.&lt;/p&gt;
&lt;p&gt;Her answer never changes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You need to run an experiment because you don&apos;t know and I don&apos;t know.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It‚Äôs not the answer they want - but it‚Äôs the only one that works.&lt;/p&gt;
&lt;p&gt;It‚Äôs a pattern I‚Äôve seen often, especially with those newer to AI development. People want definitive answers but AI doesn&apos;t work like that.&lt;/p&gt;
&lt;p&gt;This post explores how to shift from seeking certainty to building an experimental mindset - and how that shift leads to better decisions, faster progress, and ultimately better outcomes.&lt;/p&gt;
&lt;h3&gt;The Empirical Reality&lt;/h3&gt;
&lt;p&gt;If you don&apos;t know which model to use, the good news is: nobody else does either. It&apos;s not a lack of expertise. It&apos;s the nature of AI.&lt;/p&gt;
&lt;p&gt;Context shapes everything. Your data, your constraints, your requirements - they create a performance landscape unique to you.&lt;/p&gt;
&lt;p&gt;Generic model benchmarks exist but these tend to offer signals, not guarantees.
Some patterns are clear: certain models handle images better than text. Some excel only with structured data. But beyond basic heuristics, the hierarchy breaks down.&lt;/p&gt;
&lt;p&gt;That&apos;s why experienced practitioners default to experimentation. They don&apos;t assume optimal solutions exist - they experiment. Every project becomes a new question that needs validation.&lt;/p&gt;
&lt;p&gt;School rewards knowing the &quot;right&quot; answer. AI requires asking better questions.&lt;/p&gt;
&lt;h4&gt;Why Empiricism Wins&lt;/h4&gt;
&lt;p&gt;In AI, not knowing isn&apos;t a weakness. It&apos;s your edge - if you know how to use it.&lt;/p&gt;
&lt;p&gt;The most effective AI teams don&apos;t hide uncertainty - they operationalise it. They adopt not-knowing into their workflow and cultivate it through disciplined experimentation.&lt;/p&gt;
&lt;p&gt;The most dangerous phrase in AI development? &quot;Looks good to me.&quot;&lt;/p&gt;
&lt;p&gt;Moving from opinion based decisions to evidence based ones requires deliberate practice. Here&apos;s how to build those habits systematically.&lt;/p&gt;
&lt;h3&gt;Practical Strategies for an Experimental Mindset&lt;/h3&gt;
&lt;p&gt;Building an experimental mindset is like building any habit - start small, and make it deliberate.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Define metrics that matter for your goals. Technical indicators should correlate with business value:
&lt;ul&gt;
&lt;li&gt;For example say you&apos;re building a customer service chat bot and the business goal is to reduce support ticket volume. Then the response semantic similiarity score is not the right technical indicator. Something like % of chats that escalate to human agents correlates much closer to the overarching business metric.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Define what &quot;good enough&quot; means for your use case before testing anything.&lt;/li&gt;
&lt;li&gt;Build a basic, no-frills solution first. This gives you a testable anchor for comparing more complex approaches.&lt;/li&gt;
&lt;li&gt;Plan your evaluation methodology deliberately. What data will you use? How will you acquire such data? This deserves dedicated planning time.&lt;/li&gt;
&lt;li&gt;Use real data where possible, or synthetic samples generated from real user queries.&lt;/li&gt;
&lt;li&gt;Design experiments to isolate what you&apos;re actually testing. Random experimentation teaches nothing.&lt;/li&gt;
&lt;li&gt;Track why things didn&apos;t work with the same attention you give to what did. Failed experiments are compressed learning.&lt;/li&gt;
&lt;li&gt;Debate with metrics, not opinions. Show the data or acknowledge it&apos;s just preference.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Certainty is not a viable strategy in AI. The best practitioners don&apos;t chase answers - they build better experiments.&lt;/p&gt;
&lt;p&gt;The job of AI leaders is to foster this mindset and create the psychological safety that lets teams fail forward. This means creating space for &quot;I don&apos;t know&quot; during project planning. It means celebrating experiments that fail fast over assumptions that fail slowly.&lt;/p&gt;
&lt;p&gt;My friend&apos;s answer to those questions remains the same: &quot;You need to run an experiment because you don&apos;t know and I don&apos;t know.&quot;&lt;/p&gt;
&lt;p&gt;It&apos;s still not the answer people want. But teams that embrace it move faster and make better decisions because of it.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Stop Scaling Everything]]></title><description><![CDATA[I spoke this week with a company about aspects of the business that could be automated or streamlined. Their live customer sessions are ripe‚Ä¶]]></description><link>https://quantably.co/stop-scaling-everything/</link><guid isPermaLink="false">https://quantably.co/stop-scaling-everything/</guid><pubDate>Fri, 06 Jun 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I spoke this week with a company about aspects of the business that could be automated or streamlined. Their live customer sessions are ripe for turning into pre-recorded webinars. Instead, they&apos;ve decided to keep everything live. They believe in the power of real-time discussion to create shared understanding especially around complex and sometimes messy topics.&lt;/p&gt;
&lt;p&gt;It got me thinking about the scaling obsession that exists in our current business climate.&lt;/p&gt;
&lt;p&gt;Often the most unique part of a business are the things you choose NOT to scale, even when you could.&lt;/p&gt;
&lt;p&gt;Why? Because it showcases the DNA of the company. Constraints reveal values.&lt;/p&gt;
&lt;p&gt;Steve Jobs insisted the internal components of Apple devices be beautiful, even though customers would never see them. It made manufacturing harder, but it embodied obsession with perfection in every detail.&lt;/p&gt;
&lt;p&gt;The same applies to your business. Sure, you could systematise that discovery process. You could replace those strategy sessions with a standardised framework.&lt;/p&gt;
&lt;p&gt;But what if you don&apos;t?&lt;/p&gt;
&lt;p&gt;I&apos;m all for ruthless automation of repetitive, commoditised work. But also choose what stays bounded and what needs a real-time human touch.&lt;/p&gt;
&lt;p&gt;As everyone adopts the same AI tools, everything risks starting to look a bit the same. Smart non-scaling helps preserve what makes you different.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[The AI Privacy Paralysis That's Costing SMEs Everything]]></title><description><![CDATA[This data could be absolutely transformative for our business - but we can't risk putting it into AI tools. This sentiment is common. Many‚Ä¶]]></description><link>https://quantably.co/the-ai-privacy-paralysis-thats-costing-smes-everything/</link><guid isPermaLink="false">https://quantably.co/the-ai-privacy-paralysis-thats-costing-smes-everything/</guid><pubDate>Sat, 24 May 2025 00:00:00 GMT</pubDate><content:encoded>&lt;blockquote&gt;
&lt;p&gt;This data could be absolutely transformative for our business - but we can&apos;t risk putting it into AI tools.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This sentiment is common. Many businesses, especially SMEs, recognise AI&apos;s potential to transform operational efficiency but are stifled by the fear of security breaches and data exposure. The risk feels too high when client trust and sensitive information are on the line.&lt;/p&gt;
&lt;p&gt;When relationships drive your business, the stakes matter. One data leak could cost everything. Only 56% of consumers believe companies can ensure data privacy when implementing AI tools.&lt;/p&gt;
&lt;p&gt;Such skepticism is understandable.&lt;/p&gt;
&lt;p&gt;Conventional wisdom says: &quot;Sensitive data = Local deployment.&quot; But is it really that binary?&lt;/p&gt;
&lt;p&gt;In this post, you&apos;ll learn the six distinct deployment paths available - each with different trade-offs, requirements, and levels of control. Knowing these options reframes the question from &quot;should we use AI?&quot; to &quot;which approach actually fits our situation?&quot;&lt;/p&gt;
&lt;h3&gt;üõ†Ô∏è Deployment Options&lt;/h3&gt;
&lt;p&gt;Privacy and productivity are a constant trade-off. The right deployment strategy is about aligning to your specific needs. Here are the core choices.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;üíª Option 1: Lightweight Local (The Quick Fix)&lt;/summary&gt;
&lt;div style=&quot;margin-left: 1.5em;&quot;&gt;
&lt;p&gt;&lt;strong&gt;What?&lt;/strong&gt; Deploys AI models on your own device, enabling private, custom chat-based workflows.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; &lt;a href=&quot;https://ollama.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Ollama&lt;/a&gt; + &lt;a href=&quot;https://github.com/open-webui/open-webui&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Open WebUI&lt;/a&gt; running in Docker on laptops for individual use.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When?&lt;/strong&gt; This works when you need immediate privacy for simple chat based tasks but don&apos;t have technical resources.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cost estimates:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setup: $0-650 (per person if hardware upgrade required)&lt;/li&gt;
&lt;li&gt;Ongoing: $0/month&lt;/li&gt;
&lt;li&gt;Time investment: 8-12 hours initial setup and learning&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Difficulty:&lt;/strong&gt; Quick start (1-2 weeks)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Considerations&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Limited capability that won&apos;t scale beyond personal productivity&lt;/li&gt;
&lt;li&gt;Models less capable than cloud based one&lt;/li&gt;
&lt;li&gt;Need decent laptop hardware to run models&lt;/li&gt;
&lt;li&gt;Requires some technical proficiency to run models locally&lt;/li&gt;
&lt;li&gt;Works well for fixing individual productivity rather than business transformation&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;üè† Option 2: Private Infrastructure (On-Premise, Complete Control)&lt;/summary&gt;
&lt;div style=&quot;margin-left: 1.5em;&quot;&gt;
&lt;p&gt;&lt;strong&gt;What:&lt;/strong&gt; Run AI models entirely on your own physical hardware, managed and secured by your team, with no external cloud dependencies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; &lt;a href=&quot;https://vllm.ai/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;vLLM&lt;/a&gt; running a &lt;a href=&quot;https://github.com/EleutherAI/gpt-neox&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;GPT-NeoX&lt;/a&gt; LLM model on a local GPU rack sat behind a &lt;a href=&quot;https://caddyserver.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Caddy&lt;/a&gt; proxy.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When?&lt;/strong&gt; You have high-security requirements, substantial technical expertise, and budget for complete data control.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cost estimates:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setup: $19,000-65,000 (servers, GPUs, networking, installation)&lt;/li&gt;
&lt;li&gt;Ongoing: $2,600-6,500/month (power, cooling, maintenance, staff time)&lt;/li&gt;
&lt;li&gt;Time investment: 2-3 months full deployment&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Difficulty:&lt;/strong&gt; Major project (3+ months) + ongoing technical maintenance&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Considerations&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Expensive upfront hardware investment (GPUs, servers, networking)&lt;/li&gt;
&lt;li&gt;Requires dedicated technical team for setup and ongoing maintenance&lt;/li&gt;
&lt;li&gt;Complex infrastructure management and security responsibilities&lt;/li&gt;
&lt;li&gt;Significant ongoing costs for power, cooling, and updates&lt;/li&gt;
&lt;li&gt;Maximum privacy and control but substantial resource commitment&lt;/li&gt;
&lt;li&gt;Best for organisations where zero external data exposure is non-negotiable&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;‚òÅÔ∏è Option 3: Private Cloud (Dedicated Cloud, Full Control)&lt;/summary&gt;
&lt;div style=&quot;margin-left: 1.5em;&quot;&gt;
&lt;p&gt;&lt;strong&gt;What:&lt;/strong&gt; Run AI models on dedicated cloud resources that you control and configure, not shared/public SaaS.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; Deploy LLMs like Llama 3 using vLLM on dedicated AWS EC2 instances with Inferentia/Trainium chips for scalable, managed inference. Example &lt;a href=&quot;https://aws.amazon.com/blogs/machine-learning/serving-llms-using-vllm-and-amazon-ec2-instances-with-aws-ai-chips/?utm_source=chatgpt.com&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;AWS deployment guide&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When?&lt;/strong&gt; You need control and scalability, but want to avoid on-premise hardware and leverage cloud flexibility.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cost estimates:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setup: $0-2,600 (cloud integration, configuration)&lt;/li&gt;
&lt;li&gt;Ongoing: $650-3,900/month (cloud compute, storage, bandwidth)&lt;/li&gt;
&lt;li&gt;Time investment: 1-3 weeks setup and scaling&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Difficulty:&lt;/strong&gt; Medium complexity (1-2 months) + ongoing technical maintenance&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Considerations&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lower upfront cost than on-premise, but ongoing cloud spend&lt;/li&gt;
&lt;li&gt;Still requires technical expertise for secure configuration and management&lt;/li&gt;
&lt;li&gt;Data remains under your control, but is hosted offsite&lt;/li&gt;
&lt;li&gt;Easier to scale up or down as resource needs change&lt;/li&gt;
&lt;li&gt;Vendor lock-in and cloud compliance still need to be managed&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;üá™üá∫ Option 4: EU-Compliant Cloud (The Regulatory Safe Haven)&lt;/summary&gt;
&lt;div style=&quot;margin-left: 1.5em;&quot;&gt;
&lt;p&gt;EU-hosted providers offering data residency compliance and GDPR-first solutions. This suits EU businesses with strict regulatory requirements.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://aleph-alpha.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Aleph Alpha&lt;/a&gt;: A sovereign, transparent EU-based provider focused on data protection, explainability, and compliance for critical industries and the public sector.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://openai.com/index/introducing-data-residency-in-europe/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;OpenAI European Data Residency&lt;/a&gt;: Mainstream LLMs with new options for processing and storing data exclusively within the EU, helping address GDPR and client data residency requirements. Note: This is typically part of OpenAI&apos;s Enterprise plan, and specific pricing requires contacting their sales team.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cost estimates:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setup: $0-2,600 (integration and compliance review for general EU-compliant cloud services)&lt;/li&gt;
&lt;li&gt;Ongoing: $260-2,600/month (depending on usage and provider; OpenAI Enterprise pricing will vary and requires direct inquiry)&lt;/li&gt;
&lt;li&gt;Time investment: 2-4 weeks setup and compliance verification&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Difficulty:&lt;/strong&gt; Medium complexity (1-2 months)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Considerations&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Best for when regulatory requirements are your primary concern.&lt;/li&gt;
&lt;li&gt;Ongoing vendor management and contract review required&lt;/li&gt;
&lt;li&gt;User access controls and data handling policies within the cloud service still need active management.&lt;/li&gt;
&lt;li&gt;Monitoring API usage, costs, and any provider-side changes is necessary.&lt;/li&gt;
&lt;li&gt;Regularly verify that the service continues to meet your compliance obligations.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;üõ°Ô∏è Option 5: Sanitised Cloud (The Middle Path)&lt;/summary&gt;
&lt;div style=&quot;margin-left: 1.5em;&quot;&gt;
&lt;p&gt;&lt;strong&gt;What?&lt;/strong&gt; Data obfuscation combined with cloud APIs&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; &lt;a href=&quot;https://n8n.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;N8N&lt;/a&gt; jobs running data pipelines to sanitise data before calling cloud based LLM models&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When?&lt;/strong&gt; You want cloud performance with enhanced data protection and have the expertise for careful implementation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cost estimates:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setup: $3,900-10,400 (sanitisation system development)&lt;/li&gt;
&lt;li&gt;Ongoing: $390-1,950/month (cloud costs + monitoring tools)&lt;/li&gt;
&lt;li&gt;Time investment: 4-6 weeks development and testing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Difficulty:&lt;/strong&gt; Medium complexity (1-2 months) + ongoing technical maintenance&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Considerations&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requires technical expertise to implement data sanitisation properly&lt;/li&gt;
&lt;li&gt;Need robust obfuscation processes to protect sensitive information&lt;/li&gt;
&lt;li&gt;Ongoing management of privacy controls and monitoring&lt;/li&gt;
&lt;li&gt;More complex than standard cloud but less than full local infrastructure&lt;/li&gt;
&lt;li&gt;Good balance of performance and privacy for technically capable teams&lt;/li&gt;
&lt;li&gt;Success depends on quality of your data protection implementation&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;‚òÅÔ∏è Option 6: Pure Cloud (The Calculated Risk)&lt;/summary&gt;
&lt;div style=&quot;margin-left: 1.5em;&quot;&gt;
&lt;p&gt;&lt;strong&gt;What?&lt;/strong&gt; Standard cloud APIs with strong contracts and monitoring systems. Choose this when speed of deployment matters more than privacy concerns. Fastest implementation but requires ongoing risk management.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; Direct OpenAI, Anthropic, Gemini API usage in your workflows&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cost estimates:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setup: $0-1,300 (integration and monitoring setup)&lt;/li&gt;
&lt;li&gt;Ongoing: $130-1,300/month (API costs based on usage)&lt;/li&gt;
&lt;li&gt;Time investment: 1-2 weeks integration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Difficulty:&lt;/strong&gt; Quick start (1-2 weeks)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Considerations&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fastest time to market with immediate access to cutting-edge capabilities&lt;/li&gt;
&lt;li&gt;Relies on vendor privacy policies and data handling commitments&lt;/li&gt;
&lt;li&gt;Requires ongoing contract negotiation and risk monitoring&lt;/li&gt;
&lt;li&gt;Cost-effective for high-volume usage but potential vendor lock-in&lt;/li&gt;
&lt;li&gt;Suitable when competitive speed outweighs data sovereignty concerns&lt;/li&gt;
&lt;li&gt;Regular compliance audits needed to maintain oversight&lt;/li&gt;
&lt;li&gt;Privacy controls available: opt out of data training, enterprise agreements with enhanced protections, and API-only access to avoid chat history retention&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;h3&gt;Combining Approaches&lt;/h3&gt;
&lt;p&gt;In reality companies often don&apos;t pick one path. They use different approaches for different data types. Strategic planning happens on local models. Customer analysis runs through sanitised cloud. Content creation uses pure cloud APIs where speed matters more than sovereignty.&lt;/p&gt;
&lt;p&gt;Different risks, different tools. Start conservative with sensitive data, experiment freely with operational tasks. The framework scales with your comfort and capability.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;The most expensive option of all is inertia. Your competitive gap widens whilst you deliberate. Choose based on your technical capability, regulatory requirements, and risk tolerance.&lt;/p&gt;
&lt;p&gt;Start small - lightweight local deployment enables experimentation without commitment. Privacy matters, but so does momentum. Make a choice and move forward.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;56% statistic: &lt;a href=&quot;https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Consumer Perspectives of Privacy and Artificial Intelligence, IAPP&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Why Expectation Management Is Your Most Powerful AI Tool]]></title><description><![CDATA[The most successful AI projects I've led share a common trait and it's not superior technology or bigger budgets. It's a discipline that most companies overlook entirely]]></description><link>https://quantably.co/expectation-management-powerful-ai-tool/</link><guid isPermaLink="false">https://quantably.co/expectation-management-powerful-ai-tool/</guid><pubDate>Sat, 10 May 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;The most successful AI projects I&apos;ve led share a common trait and it&apos;s not superior technology or bigger budgets. It&apos;s a discipline that most companies overlook entirely&lt;!-- excerpt --&gt;: expectation setting.&lt;/p&gt;
&lt;p&gt;By the end of this post, you&apos;ll understand how to master the three critical layers of AI expectation setting and implement four practical approaches that will dramatically improve your project outcomes.&lt;/p&gt;
&lt;h2&gt;Why AI Demands a New Approach&lt;/h2&gt;
&lt;p&gt;You need the right technology, talent, and infrastructure. Those are a given. But when AI projects fail, it&apos;s rarely due to technical shortcomings. Expectation setting makes or breaks them.&lt;/p&gt;
&lt;p&gt;Expectation setting isn&apos;t a new idea, but it&apos;s especially critical in AI. Three key factors make it challenging:&lt;/p&gt;
&lt;h4&gt;1. The Hype Factor&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;AI projects suffer from mismatched expectations more than other tech areas&lt;/li&gt;
&lt;li&gt;Media coverage creates unrealistic benchmarks&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2. Hidden Complexity&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;It&apos;s not always clear what AI can actually do (and what it can&apos;t)&lt;/li&gt;
&lt;li&gt;&apos;Hidden&apos; work behind the scenes isn&apos;t obvious to stakeholders&lt;/li&gt;
&lt;li&gt;Example: Customers confused when data preparation is allocated a month&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;3. Non-linear Progress&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Traditional roadmaps promise features by set dates, but AI progress isn&apos;t linear&lt;/li&gt;
&lt;li&gt;You might reach 60% accuracy quickly, then spend months chasing 85%&lt;/li&gt;
&lt;li&gt;This affects both internal teams and external stakeholder expectations&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;The Three Layers Where AI Expectations Typically Fail&lt;/h2&gt;
&lt;p&gt;These challenges are why I&apos;ve found it helpful to structure commonly missed AI expectation management across three categories:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Technical Reality Expectations&lt;/li&gt;
&lt;li&gt;Process Expectations&lt;/li&gt;
&lt;li&gt;Outcome Expectations&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/81889485a105d071037e69d53d0cc14b/71c1d/three-layers.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 66.45569620253164%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsTAAALEwEAmpwYAAABeUlEQVR42qVS2ZKCMBD0/39qa8vVpZBTlPVCjkAIIahAzPN2xPWo0qelulIznemZCTOj8z++0bsLdTekemZuthaf2q7rpUbX9xcDhCbhynPb9bCHE1dgQMOWECultlEynhiGaeH8+PxahKvmcCJ5ObPd8dRYbaJaHGtxyAidGrPJt+kvQl4feil1ZVKU2ygGdvtks9tnOdXiooziFEhJwcUBSLIcLmKAknEpL23DsVzfcjzb9U3LRRYuml2cgkHxcLXhdUNZ5QVLBLj+AnxK8rNSI7S+TzL4jh+Ytrv8WVPGSU6jOIPS8eaoXFZ1kpFwvXX9ACkcLwCl3ywvlU3Lsb05ym6iGM9D2/s4Qy7wcUrq5oi2/SA0TBsZbXdeUHYRS1lWPC9ZTivUQMqqFghFfdiEDkyDznPKbqi4gFCLGRdoDGDDya/igaSs1mLRlAwBAhhirn+7bfVUb2j/pnpnOj3z9jFgmPNtY9SbJVPPhnpgXqynfLWtL8lfWtzH82WBWU0AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Three Layers of AI Expectation Setting&quot;
        title=&quot;&quot;
        src=&quot;/static/81889485a105d071037e69d53d0cc14b/f058b/three-layers.png&quot;
        srcset=&quot;/static/81889485a105d071037e69d53d0cc14b/c26ae/three-layers.png 158w,
/static/81889485a105d071037e69d53d0cc14b/6bdcf/three-layers.png 315w,
/static/81889485a105d071037e69d53d0cc14b/f058b/three-layers.png 630w,
/static/81889485a105d071037e69d53d0cc14b/40601/three-layers.png 945w,
/static/81889485a105d071037e69d53d0cc14b/78612/three-layers.png 1260w,
/static/81889485a105d071037e69d53d0cc14b/71c1d/three-layers.png 1536w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;Layer 1: Technical Reality Expectations&lt;/h3&gt;
&lt;p&gt;This layer addresses misalignments in understanding AI&apos;s capabilities. Stakeholders must grasp what the technology can realistically do, and critically, what it can&apos;t.&lt;/p&gt;
&lt;p&gt;A key learning for me: I once had a client who was baffled when a model couldn&apos;t predict accurately on new data. They didn&apos;t understand the model&apos;s limits - how it struggles to generalise beyond what its seen in training. That wasn&apos;t just a technical detail. It nearly derailed the whole project.&lt;/p&gt;
&lt;p&gt;Another common issue? Judging a model by a few cherry-picked bad predictions. It&apos;s smart to investigate failures, but that shouldn&apos;t define overall performance. Still, I see customers fixate on these outliers again and again.&lt;/p&gt;
&lt;h3&gt;Layer 2: Process Expectations&lt;/h3&gt;
&lt;p&gt;Process expectation setting is about aligning on AI project workflows. Stakeholders often express surprise at the data exploration timeline. They&apos;re eager for outcomes but are not always aware of the process needed to get there.&lt;/p&gt;
&lt;p&gt;The cyclical nature of AI development is another area often needing alignment. AI projects rarely fit linear GANTT charts. Instead, they iterate: BUILD -&gt; MEASURE -&gt; LEARN feedback loops. This refines model performance through rapid experimentation, where many experiments can and should &quot;fail&quot;.&lt;/p&gt;
&lt;p&gt;These aren&apos;t failures, but valuable learning opportunities. Without careful expectation management however, these efforts risk being perceived as a lack of progress.&lt;/p&gt;
&lt;h3&gt;Layer 3: Outcome Expectations&lt;/h3&gt;
&lt;p&gt;Communicating AI project results demands a tailored approach. Internal or external, the audience dictates the level of detail and language used.&lt;/p&gt;
&lt;p&gt;I&apos;ve witnessed first hand executives visibly disengage as detailed F1-scores for a multi-class classifier were presented. The communication wasn&apos;t audience-appropriate. Execs and capital allocators need technical KPIs translated into business outcomes or cost savings to speak their language.&lt;/p&gt;
&lt;p&gt;Model maintenance is another frequent point of misalignment related to outcomes. AI systems are rarely &quot;fire and forget.&quot; Data distributions drift, requiring maintenance in the form of monitoring and periodic model retraining or refreshing the data.&lt;/p&gt;
&lt;h3&gt;Revolutionary Approaches for the AI Era&lt;/h3&gt;
&lt;p&gt;Recognising these three layers reveals common pain points. Despite this, traditional approaches to expectation management often perpetuate the problems they attempt to solve. Below are four approaches I use that directly address these challenges.&lt;/p&gt;
&lt;h4&gt;1. Create dual reporting structures&lt;/h4&gt;
&lt;p&gt;Dual reporting means sharing content that is tailored to the audience. Remember the executive who disengaged during F1-score discussions (Layer 3)? Same project, different languages. What matters to one group may be irrelevant to another.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/ec397c560e3f72c8575820b7f8c31684/71c1d/reporting-table.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 66.45569620253164%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAACRUlEQVR42j1T2XLaQBDk/38oRXAZKAebW4A4BBIShzjEoRtISDmd6QH7YWql3Z2e6enewv3PFXkWI00jjYxr8lizNEYmZ/xO4hCXPNFI4jOSJNS86yXVe8wlVuF2zeDObWw3a2z8JXZbH578LxZzrFceVksPy6Wrq2WN4Lk2joed5MxgzyzMZhO5t0Cw32ghAcz1Eg+n1hjWZITlwoVjTzUm4yFs21KAZuMDtdqbFF9h7sxQr7+jUnmFOeghFrDwfECBFAgY7LdSeY8oPCqQL90GwVa78dcLdDotjEemdkkAfrNYv9fF0OwrRhSdBFBmsJGKhtFGp93EoG8oVVJoNutotRoIn0U2/gqz6QSuJPN7IMCOdPrv86/e0Q45Q891tKphdNAQGpZQP58CGN02RsOB0hmPTaykkL9efgNXq2VUyq+aT/HITgE5j6EkUhwqdToG2qHnOZjL7E7HvVLtScGqzIwiELgt3ZNRKopnWfQA/H3LFfClVNSKefawBYUoFn+g/PqiyUcBZSF2RwBS5ezMQV/zySLmDOkjXuKASTc8HzXSJFarHIKdes00e+iKMO+i8hdtOmIk4nCfd+nNhw+ftuGcCPAAPaD+UVNK/Oaeggh1MqBvV+JPMrnfb7qnHZKy40xVzVLpp25+BWfEIEXOB/jUYBMU5ddbVYvSQvQuX9O3yhw0Dcs58X+/87WDhTfXbrjH7ulX3qVYtBf9yrOH0hEKVPV6yXRO9GT+fK8M7rMg3yz3NbJE/y95qmfM48rgW/4PTPC048dih6wAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Example: Reporting for Different Stakeholders&quot;
        title=&quot;&quot;
        src=&quot;/static/ec397c560e3f72c8575820b7f8c31684/f058b/reporting-table.png&quot;
        srcset=&quot;/static/ec397c560e3f72c8575820b7f8c31684/c26ae/reporting-table.png 158w,
/static/ec397c560e3f72c8575820b7f8c31684/6bdcf/reporting-table.png 315w,
/static/ec397c560e3f72c8575820b7f8c31684/f058b/reporting-table.png 630w,
/static/ec397c560e3f72c8575820b7f8c31684/40601/reporting-table.png 945w,
/static/ec397c560e3f72c8575820b7f8c31684/78612/reporting-table.png 1260w,
/static/ec397c560e3f72c8575820b7f8c31684/71c1d/reporting-table.png 1536w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h4&gt;2. Frame expectations through cost of omission rather than the benefits of inclusion&lt;/h4&gt;
&lt;p&gt;When clients question the month allocated for data preparation (Layer 2). Instead of defending the timeline, flip the conversation and help explore what happens without data preparation work. Raise the question: &quot;What&apos;s the cost of NOT doing this step?&quot; Frame it in terms of outcomes the stakeholder is primarily concerned with - predictive accuracy, frauds detected, chatbot hallucinations. This is not about being negative, it&apos;s about transparency and clarity on the importance of certain parts of a project.&lt;/p&gt;
&lt;h4&gt;3. Create a failure library documenting every dead end, flawed assumption or failed experiment&lt;/h4&gt;
&lt;p&gt;For stakeholders who view AI iteration as a lack of progress (Layer 2), a failure library reframes setbacks as assets. When teams document what didn&apos;t work, &quot;failure&quot; becomes intelligence.
This compounds as new people join. Instead of repeating dead ends, they see what&apos;s been tried. Smart teams track failures, not just wins. Document every wrong turn.&lt;/p&gt;
&lt;h4&gt;4. Preemptively reframe project paradigms&lt;/h4&gt;
&lt;p&gt;The fourth technique is straightforward but powerful: explicitly reset project paradigms from the outset.&lt;/p&gt;
&lt;p&gt;Before kickoff, hold dedicated sessions where you clearly establish: &quot;This AI project will not look like traditional technology projects.&quot; Outline the specific differences in timeline patterns, evaluation metrics, and delivery cadence.&lt;/p&gt;
&lt;p&gt;This preemptive paradigm shift prevents stakeholders from applying the wrong mental models from previous experience. By addressing these differences explicitly and early, you establish new criteria for success before misaligned expectations can take root.&lt;/p&gt;
&lt;p&gt;To do this effectively, use concrete language and analogies that connect AI to business realities.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Expectation setting is more than a project management checkbox; it‚Äôs often the difference between AI that delivers and AI that doesn‚Äôt. The best leaders manage mindsets as well as timelines.&lt;/p&gt;
&lt;p&gt;In AI projects, the real challenge isn‚Äôt simply a lack of knowledge, but the need for behavioral change. Think of it like marathon training: progress isn‚Äôt linear, and setbacks are part of the journey. Failed experiments and plateaus in model performance aren‚Äôt signs of failure - they‚Äôre essential steps in development.&lt;/p&gt;
&lt;p&gt;To improve outcomes, start by mapping out the three layers: technical reality, process, and outcomes. Identify where expectations are most misaligned. Use dual reporting, frame the cost of skipping steps, document failures, and reset project paradigms before misconceptions take root.&lt;/p&gt;
&lt;p&gt;Perfection isn‚Äôt required. What matters is being clear, honest, and adaptable. In AI, progress comes from learning and doubling down on what works.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Using Claude to Create Professional PowerPoint Presentations]]></title><description><![CDATA[Creating presentations often takes considerable time. By combining Claude Desktop with MCPs and a custom PowerPoint template, you can automate much of this process.]]></description><link>https://quantably.co/using-mcps-to-generate-presentations-fast/</link><guid isPermaLink="false">https://quantably.co/using-mcps-to-generate-presentations-fast/</guid><pubDate>Fri, 18 Apr 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Creating presentations often takes considerable time. By combining Claude Desktop with MCPs and a custom PowerPoint template, you can automate much of this process. &lt;!-- excerpt --&gt; This guide explains how to configure Claude to generate well-structured presentations based on your specific requirements and theme.&lt;/p&gt;
&lt;h2&gt;The system I use for fast slide creation&lt;/h2&gt;
&lt;p&gt;The three main parts to the system are the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Claude Desktop App&lt;/li&gt;
&lt;li&gt;MCPs:
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;fetch&lt;/code&gt; - for researching information for the slides&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;sequential-thinking&lt;/code&gt; - to allow claude to think through the stages needed to create the slides&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;desktop-commander&lt;/code&gt; - to allow claude to execute shell commands such as a &lt;code class=&quot;language-text&quot;&gt;pandoc&lt;/code&gt; for slide creation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A Powerpoint template that matches the output style you want&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Setting Up Your Environment&lt;/h2&gt;
&lt;h3&gt;Essential Prerequisites&lt;/h3&gt;
&lt;h4&gt;1. Install Pandoc&lt;/h4&gt;
&lt;p&gt;Download and install Pandoc from the &lt;a href=&quot;https://pandoc.org/&quot;&gt;official website&lt;/a&gt;. Pandoc is a universal document converter for converting between markup formats, which is used here for transforming Claude&apos;s markdown output into PowerPoint format.&lt;/p&gt;
&lt;h4&gt;2. Configure MCP Servers&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Open Claude Desktop&lt;/li&gt;
&lt;li&gt;Navigate to Settings &gt; Developer &gt; Edit Config&lt;/li&gt;
&lt;li&gt;Add the following MCP servers to your configuration:
&lt;ul&gt;
&lt;li&gt;fetch&lt;/li&gt;
&lt;li&gt;sequential thinking&lt;/li&gt;
&lt;li&gt;desktop commander&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Save changes and restart your Claude instance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is what my MCP configuration looks like:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;json&quot;&gt;&lt;pre class=&quot;language-json&quot;&gt;&lt;code class=&quot;language-json&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;token property&quot;&gt;&quot;mcpServers&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;token property&quot;&gt;&quot;fetch&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;token property&quot;&gt;&quot;command&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;uvx&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;token property&quot;&gt;&quot;args&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;
     &lt;span class=&quot;token string&quot;&gt;&quot;mcp-server-fetch&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;token string&quot;&gt;&quot;--ignore-robots-txt&quot;&lt;/span&gt;
   &lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;token property&quot;&gt;&quot;sequential-thinking&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;token property&quot;&gt;&quot;command&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;npx&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;token property&quot;&gt;&quot;args&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;
     &lt;span class=&quot;token string&quot;&gt;&quot;-y&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;token string&quot;&gt;&quot;@modelcontextprotocol/server-sequential-thinking&quot;&lt;/span&gt;
   &lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;token property&quot;&gt;&quot;desktop-commander&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;token property&quot;&gt;&quot;command&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;npx&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;token property&quot;&gt;&quot;args&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;
     &lt;span class=&quot;token string&quot;&gt;&quot;-y&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;token string&quot;&gt;&quot;@wonderwhy-er/desktop-commander&quot;&lt;/span&gt;
   &lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;3. Verify Configuration&lt;/h4&gt;
&lt;p&gt;After restarting, check that all three MCP servers appear correctly in your settings.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/9bd90b5f0e1886e7e66b4d00deb5e7e5/569c6/mcps-config.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 74.68354430379746%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABYlAAAWJQFJUiTwAAABQElEQVR42r2UfWuDMBCH/Ribls6XGI3G+G6hUDao0O//iW73O20Hpes2kP3xeIkxT5LT03O5JsOkaUJaK0FxW6kvch7PslSe+Y7rXM/yg5UtZALI85Tq2jIVNY2TOAyttKuqJLcibWclAiyaJDF5iYppGjuy1lAU7XmVhAUd9X1DXVdT2zoB42WZC0WRMWgbiWARRuQpFfHqFa9WUhy/EfrT1DOd3AclBCbliZqj5r5e7619RO6LEJdbHtY8nU5HulxmmucPOp/fyWJnPOEZEEoOIczWhALkETnEzq6xwnF/EvIuMz62CPWdEMdfXszCb4RmPfpmwuXIGwpBpDYW3t7yvwidK7gCim2EkIxjS4fDwNXi/i68L3KUF8pt5JLEbvGNGa7xZ+AfIMIw3NNuF9zhk++/Mi8UBP6D8cfEcUif9ZW455KkCW4AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Verified MCP Servers in Claude Desktop Settings&quot;
        title=&quot;&quot;
        src=&quot;/static/9bd90b5f0e1886e7e66b4d00deb5e7e5/f058b/mcps-config.png&quot;
        srcset=&quot;/static/9bd90b5f0e1886e7e66b4d00deb5e7e5/c26ae/mcps-config.png 158w,
/static/9bd90b5f0e1886e7e66b4d00deb5e7e5/6bdcf/mcps-config.png 315w,
/static/9bd90b5f0e1886e7e66b4d00deb5e7e5/f058b/mcps-config.png 630w,
/static/9bd90b5f0e1886e7e66b4d00deb5e7e5/40601/mcps-config.png 945w,
/static/9bd90b5f0e1886e7e66b4d00deb5e7e5/78612/mcps-config.png 1260w,
/static/9bd90b5f0e1886e7e66b4d00deb5e7e5/569c6/mcps-config.png 1674w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;Preparing Your PowerPoint Template&lt;/h3&gt;
&lt;p&gt;This step is optional but a template can be used to ensure your AI-generated slides match a given style&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Find a Suitable Theme&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Download a PowerPoint theme that matches your brand or presentation style&lt;/li&gt;
&lt;li&gt;Microsoft 365 offers various template &lt;a href=&quot;https://create.microsoft.com/en-us/powerpoint-templates&quot;&gt;available here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Save as Template&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Open PowerPoint and select File &gt; Save As Template&lt;/li&gt;
&lt;li&gt;Ensure the file has the proper template extension (.potx)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Label Slide Layouts in Slide Master&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Open the template and navigate to View &gt; Slide Master&lt;/li&gt;
&lt;li&gt;In order for Pandoc to correctly use the template. You need to label each slide type clearly as &lt;a href=&quot;https://pandoc.org/chunkedhtml-demo/10.1-structuring-the-slide-show.html&quot;&gt;described here&lt;/a&gt; (e.g., Title Slide, Section Header, Content Slide etc.)&lt;/li&gt;
&lt;li&gt;These labels help Claude understand which layout to use for different content.&lt;/li&gt;
&lt;li&gt;Ensure that each pandoc label is mapped to a slide name in ppt. Note: Some templates will already have the names like &quot;Section Header&quot; used, so you can either use them or change to a different slide that you prefer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/ee8415dec63ccdd454fa17546146db53/38bc0/slide-naming.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 51.26582278481012%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAACSUlEQVR42n2Sy09TQRTG7x9CQlyBLeVR2tvyqsREAhrcIG7RGCUhws6FiS6IMRGCCGo0xq2i+EBMecSFpCA2JDWg0EKx1oWEh1AKt1a4bW/7c+6lENnwJSeTc+bMN9+c+SS7rZTPnyYIBYOMDg0x4nbTfOUyOTk5FFtLqCqTqT9VjatcxiUXU2A6jtlsPgiTyUR+fj55eXlYLBakCoedqQkPszPTTE9NEfwe5Hr7TZ48ekxD4zlcVZXUn66j4Wwd52squN9zD6/Xi8fjYXx8nMnJSXw+H7NzczQ97ERylTmJxxR0aMmksd5+0M0XQe4V8XFsjODiIoH5BQILiyyvrBDd2mJb2UaJxfgTj5NJp41zrR9eIzlKrbzpe4773QCDr/pxu9/T3NbC/JzfaIqJQzs7OyQSCVRVRdM0I9friqIQF4Rb4gIdV4dfIBUUmLE7nJTaZKxWGyXlFZSdqeVnKGQ06c2RSISkINKykRQv0eub0SiaUKelUnsKR18iWQRh5YlqqqpPYpOdmGx2nLU1B4Qp0fw7EmUjqyKdfV4qpbG2scnmtkImk8kS9iOVFBdxp6ODnt5e7nZ10SGG3nixiYVA4IBQVRPs7qoGmZ7vKU0bI9gVe6l9hUN9SE6HzNrqqthQSYo56bjR3cm36ZlDivah5/uK/q/paBt8Jj5FtrO09IuImMfG+jp/xW3XbrUz+HaAcDiM3+8nINQeFX5hmVD4B5ee9iDpxh4ZHjH8NCG85fs6w4XWFo7l5mIpLDxk4qNCN3hhURH/AEY9XLdh89rKAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Renaming slide layouts in PowerPoint Slide Master view for Pandoc compatibility&quot;
        title=&quot;&quot;
        src=&quot;/static/ee8415dec63ccdd454fa17546146db53/f058b/slide-naming.png&quot;
        srcset=&quot;/static/ee8415dec63ccdd454fa17546146db53/c26ae/slide-naming.png 158w,
/static/ee8415dec63ccdd454fa17546146db53/6bdcf/slide-naming.png 315w,
/static/ee8415dec63ccdd454fa17546146db53/f058b/slide-naming.png 630w,
/static/ee8415dec63ccdd454fa17546146db53/40601/slide-naming.png 945w,
/static/ee8415dec63ccdd454fa17546146db53/78612/slide-naming.png 1260w,
/static/ee8415dec63ccdd454fa17546146db53/38bc0/slide-naming.png 2834w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;
&lt;em&gt;Right click slide in master view to rename to pandoc naming convention&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Creating Your Presentation with Claude&lt;/h2&gt;
&lt;h3&gt;Setting Up Your Claude Project&lt;/h3&gt;
&lt;p&gt;To orchestrate the whole workflow, I create a Claude Project that I configure with the Project Instructions shown below:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;markdown&quot;&gt;&lt;pre class=&quot;language-markdown&quot;&gt;&lt;code class=&quot;language-markdown&quot;&gt;You are an experienced slide deck creator with expertise in crafting professional, visually appealing presentations. Your skills in information organization, visual communication, and audience engagement make you the perfect creator for compelling PowerPoint presentations. Your mission is to:

Search for the information on [TOPIC] and create a presentation based on your findings. The target audience is [AUDIENCE] and the purpose is to [PURPOSE]. The presentation should be [NUMBER] slides long and convey information in a clear, engaging, and professional manner.

You&apos;ll need to follow these steps in order:

&lt;span class=&quot;token list punctuation&quot;&gt;1.&lt;/span&gt; Gather information on [TOPIC] using the fetch tool
&lt;span class=&quot;token list punctuation&quot;&gt;2.&lt;/span&gt; Plan your presentation structure with a variety of slide layouts
&lt;span class=&quot;token list punctuation&quot;&gt;3.&lt;/span&gt; Create a markdown file in [WORKINGDIR]/[FILENAME].md with the presentation content
&lt;span class=&quot;token list punctuation&quot;&gt;4.&lt;/span&gt; Convert the markdown file to PowerPoint using pandoc

For the markdown structure, use these formats to create diverse slide types (you do not need to use all, only vary as appropriate to the content):

IMPORTANT: Always include blank lines before and after lists. Proper spacing is essential for markdown formatting to render correctly.

&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;##&lt;/span&gt; Title Slide&lt;/span&gt;

Use the YAML metadata block at the top of your document:

&lt;span class=&quot;token code&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;token code-language&quot;&gt;markdown&lt;/span&gt;
&lt;span class=&quot;token code-block language-markdown&quot;&gt;&lt;span class=&quot;token front-matter-block&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;token front-matter yaml language-yaml&quot;&gt;title: &quot;Your Presentation Title&quot;
subtitle: &quot;Optional Subtitle&quot;
author: &quot;Presenter Name&quot;
date: &quot;Date of Presentation&quot;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;---&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;/span&gt;

&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;#&lt;/span&gt; Section Title Slides&lt;/span&gt;

Use level 1 headings (#) for major section divisions:

&lt;span class=&quot;token code&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;token code-language&quot;&gt;markdown&lt;/span&gt;
&lt;span class=&quot;token code-block language-markdown&quot;&gt;&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;#&lt;/span&gt; Section Title Here&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;/span&gt;

&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;#&lt;/span&gt; Content Slides with Bullet Points&lt;/span&gt;

Use level 2 headings (##) with unordered lists:

&lt;span class=&quot;token code&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;token code-language&quot;&gt;markdown&lt;/span&gt;
&lt;span class=&quot;token code-block language-markdown&quot;&gt;&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;##&lt;/span&gt; Content Slide Title&lt;/span&gt;

&lt;span class=&quot;token list punctuation&quot;&gt;-&lt;/span&gt; First bullet point
&lt;span class=&quot;token list punctuation&quot;&gt;-&lt;/span&gt; Second bullet point
  &lt;span class=&quot;token list punctuation&quot;&gt;-&lt;/span&gt; Sub-bullet point&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;/span&gt;

&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;#&lt;/span&gt; Two-Column Slides&lt;/span&gt;

Use div containers with specific attributes:

&lt;span class=&quot;token code&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;token code-language&quot;&gt;markdown&lt;/span&gt;
&lt;span class=&quot;token code-block language-markdown&quot;&gt;&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;##&lt;/span&gt; Two-Column Slide Title&lt;/span&gt;

::: {.columns}
:::: {.column width=&quot;40%&quot;}
Left column content here
::::
:::: {.column width=&quot;60%&quot;}
Right column content here
::::
:::&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;/span&gt;

&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;#&lt;/span&gt; Image Slides&lt;/span&gt;

Include images with captions:

&lt;span class=&quot;token code&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;token code-language&quot;&gt;markdown&lt;/span&gt;
&lt;span class=&quot;token code-block language-markdown&quot;&gt;&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;##&lt;/span&gt; Image Slide Title&lt;/span&gt;

&lt;span class=&quot;token url&quot;&gt;&lt;span class=&quot;token operator&quot;&gt;!&lt;/span&gt;[&lt;span class=&quot;token content&quot;&gt;Image Caption&lt;/span&gt;](&lt;span class=&quot;token url&quot;&gt;image_url&lt;/span&gt;)&lt;/span&gt;{width=70%}&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;/span&gt;

&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;#&lt;/span&gt; Table Slides&lt;/span&gt;

Create tables using markdown syntax:

&lt;span class=&quot;token code&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;token code-language&quot;&gt;markdown&lt;/span&gt;
&lt;span class=&quot;token code-block language-markdown&quot;&gt;&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;##&lt;/span&gt; Table Slide Title&lt;/span&gt;

&lt;span class=&quot;token table&quot;&gt;&lt;span class=&quot;token table-header-row&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token table-header important&quot;&gt; Header 1 &lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token table-header important&quot;&gt; Header 2 &lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token table-header important&quot;&gt; Header 3 &lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;
&lt;/span&gt;&lt;span class=&quot;token table-line&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;----------&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;----------&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;----------&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;
&lt;/span&gt;&lt;span class=&quot;token table-data-rows&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token table-data&quot;&gt; Row 1    &lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token table-data&quot;&gt; Data     &lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token table-data&quot;&gt; Data     &lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token table-data&quot;&gt; Row 2    &lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token table-data&quot;&gt; Data     &lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token table-data&quot;&gt; Data     &lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;/span&gt;

&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;#&lt;/span&gt; Quote Slides&lt;/span&gt;

Use blockquotes for emphasis:

&lt;span class=&quot;token code&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;token code-language&quot;&gt;markdown&lt;/span&gt;
&lt;span class=&quot;token code-block language-markdown&quot;&gt;&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;##&lt;/span&gt; Quote Slide Title&lt;/span&gt;

&lt;span class=&quot;token blockquote punctuation&quot;&gt;&gt;&lt;/span&gt; Important quote or emphasized text here
&lt;span class=&quot;token blockquote punctuation&quot;&gt;&gt;&lt;/span&gt; &lt;span class=&quot;token list punctuation&quot;&gt;-&lt;/span&gt; Source of the quote&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;/span&gt;

&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;#&lt;/span&gt; Incremental Reveal Slides&lt;/span&gt;

Use the incremental class for step-by-step reveals:

&lt;span class=&quot;token code&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;token code-language&quot;&gt;markdown&lt;/span&gt;
&lt;span class=&quot;token code-block language-markdown&quot;&gt;&lt;span class=&quot;token title important&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;##&lt;/span&gt; Incremental Slide&lt;/span&gt;

::: incremental
&lt;span class=&quot;token list punctuation&quot;&gt;-&lt;/span&gt; This point appears first
&lt;span class=&quot;token list punctuation&quot;&gt;-&lt;/span&gt; Then this point
&lt;span class=&quot;token list punctuation&quot;&gt;-&lt;/span&gt; Finally this point
:::&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;```&lt;/span&gt;&lt;/span&gt;

Format all content slides with:

&lt;span class=&quot;token list punctuation&quot;&gt;-&lt;/span&gt; Clear, concise headings as slide titles
&lt;span class=&quot;token list punctuation&quot;&gt;-&lt;/span&gt; Appropriate content layout based on the slide type
&lt;span class=&quot;token list punctuation&quot;&gt;-&lt;/span&gt; Citations where relevant

Use [TEMPLATE] as the template for pandoc
Use [WORKINGDIR] as the directory for where slides should be created
Use [FILENAME] as the name of the powerpoint slides to create

Use fetch to perform web content searches
Use execute_command to execute pandoc commands
Use the sequential-thinking tool to think through how you will solve this problem step-by-step before starting.

First create the markdown file:
execute_command &quot;echo &apos;YOUR_MARKDOWN_CONTENT&apos; &gt; [WORKINGDIR]/[FILENAME].md&quot;

Then convert it to PowerPoint:
execute_command &quot;pandoc [WORKINGDIR]/[FILENAME].md -o [WORKINGDIR]/[FILENAME].pptx --reference-doc=[TEMPLATE] --slide-level=2&quot;

When a chat is first created, ask the user for all of the [] placeholder information.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, when you want to create your slides, you can just start a chat a paste all the information required like the example shown below:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;markdown&quot;&gt;&lt;pre class=&quot;language-markdown&quot;&gt;&lt;code class=&quot;language-markdown&quot;&gt;[TOPIC] The New Forest: Historical Evolution and Heritage
[AUDIENCE] History enthusiasts, visitors, and locals interested in learning about the New Forest&apos;s past
[PURPOSE] To highlight key historical developments of the New Forest from its royal designation to present day, showcasing how human activity has shaped the landscape over centuries
[NUMBER] 10-12 slides
[WORKINGDIR] /Users/Peter/Desktop/test-slides
[TEMPLATE] /Users/Peter/Documents/slide\ templates/Light\ modernist\ design.potx
[FILENAME] new-forest-history.pptx&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Executing the Slide Creation Process&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Create a dedicated folder on your computer as working directory for the project&lt;/li&gt;
&lt;li&gt;Start a chat inside your Claude Project and paste in the details about the slides you want to create&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/c3efbe8a808e3deb47d14bc2e245fa74/573d3/prompt.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 100.63291139240506%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAABYlAAAWJQFJUiTwAAACmElEQVR42qVU25KaQBD1R1JuVhFQRFBEAcEbuF6iq7umKpXX/P83dPr0MAgxecpD0z0zzOnTt2l1u68UhhMyTYNeXtrU63X/S1qdzldarVIaDgfUbn95+gGOLMsgk8WyTVmbVo/3euWZ0hUgPqPRkObzKcXxvBKsoyikWRhQEIxpMvErXZeQz0HGMDoKEAYOsmxBaZoI2GIRU5JELHMK+AwXXNcRDee+P5K1jqARMgA9z2WQiGazqYBBAK5AI7GzLBEHAALoYGBXrP4KiItRNKvYwQEAYMPRfB5SzOcIUa/HY+8JtAEoABwyGC05BVgDOI5nApamytl0OpF8oiD/ZKgucjHYOwBxWYUfVXmFRh7RGRC0HO7XWQogcoKiQJbLhQo7VuEmDLhIlCDUP6uMsEGoAQivCAkhgh1+RNKx7zj9htbV1nsgA7sBGHBOwC4pQ1suU2l22LqdRHiN/aVEw5XnPUxZE5A/gdsnl73ZtkX9/kNsngytISiCtsHOdQeyZ2F6yn5sdZhhHjBt26BOVyW3nui67Th2KQzGrHzOHfKHiuu+lNF75WrVK1YXHYpi12tos2Rmmo+JaYF+kW9ovy+oKDaU52va7XLWG1qvMskRBMlXU+KIhnjesBRXzgHaQo5OpwPdbu90PO7pcHhj8J3YAC6KLettrS8folvmCXD/ltPlfKQDA+XbtYAAdL3OZBzRTuhB5Kr+8mgg5NL3aoCftwv9/PGd7h/vdL2e6X6/0efHlW7XC31j9idmixToxkdboYW27HDFrTPyRtQfOlJtyWGMF6XsN0wHmhxjBlY6d2CDZwsCG/OMMUUPp6FP53hMXYOLgnLLj/yTGievCkW/fRpEg2IfzvAAT6YBFXFAv7YzMkyTfgPad3Xta3qLggAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Prompting the system for a new slide deck&quot;
        title=&quot;&quot;
        src=&quot;/static/c3efbe8a808e3deb47d14bc2e245fa74/f058b/prompt.png&quot;
        srcset=&quot;/static/c3efbe8a808e3deb47d14bc2e245fa74/c26ae/prompt.png 158w,
/static/c3efbe8a808e3deb47d14bc2e245fa74/6bdcf/prompt.png 315w,
/static/c3efbe8a808e3deb47d14bc2e245fa74/f058b/prompt.png 630w,
/static/c3efbe8a808e3deb47d14bc2e245fa74/40601/prompt.png 945w,
/static/c3efbe8a808e3deb47d14bc2e245fa74/78612/prompt.png 1260w,
/static/c3efbe8a808e3deb47d14bc2e245fa74/573d3/prompt.png 1650w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;
&lt;em&gt;Example of providing the required placeholder information to Claude via chat.&lt;/em&gt;&lt;/p&gt;
&lt;ol start=&quot;3&quot;&gt;
&lt;li&gt;As the execution starts you will be asked to allow plugins access to your file system when prompted&lt;/li&gt;
&lt;li&gt;Monitor as Claude:
&lt;ul&gt;
&lt;li&gt;Researches your topic&lt;/li&gt;
&lt;li&gt;Structures the presentation&lt;/li&gt;
&lt;li&gt;Creates the slides using your template&lt;/li&gt;
&lt;li&gt;Saves the completed PowerPoint file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Reviewing and Refining&lt;/h3&gt;
&lt;p&gt;Once Claude completes the process:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Check your output directory for the generated PowerPoint file (sometimes on first open you will need to repair the slides, but mostly after this things look good)&lt;/li&gt;
&lt;li&gt;Open and review the content and structure&lt;/li&gt;
&lt;li&gt;Make any necessary adjustments to styling, content ordering, or visual elements&lt;/li&gt;
&lt;li&gt;Consider providing feedback to Claude for future improvements this can be used to quickly iterate on changes&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/aa71ae88940b95504537fa76eea64f41/09d8d/prez.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 58.86075949367089%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACjklEQVR42oVTS08TURTuH2npQwsyLZ0+EaQ0tEQTd2oriBuM6dr/YGSBJLowshEXtEWFuCCuq9AKfVDQgtGVC02U0s4UZvoYStvp570XMEZNuMmX88id73z3zDkah7MPnMUCu90OC8eB53nmOxwO5judTrjdbhZbrVZwnAVW3o7hYR98Pi/8fj8Co6MY9Q7g9pAFmomJW5icvINwOIyx8XE4PW7yEQejyQST0QiDwQBdVxe0Wh30ej1M580wczZGzvf1wtzTg3Pkrqu3B0MuHpp0OoW6ogBqB2WlBqffhxFSfXFpCfPz84jFYlhYWGD22I8hGokgGo0iEokyu7y8jLvT96Hr7obm1csX2NzMIb+1hWQmBetFN8aCIbTbKoqlEg4kCbJcgUSsJMmoVqsnOfkkJ4GemXwSOqJS8+59EkVZQnF/H98ORPC+Swheu84uNZtNHB0dMbSI3/wDNKeqKincZnenM3FoLxCFybUk5HoNQlnE18IP8N5B3LwRJB1QUSIKy+Uy9kkxQRAhiOLvmKqs1xXUarVjhbmVY8I3r5fwOf8RO7kcMtkUHIP9CAUpYQeFvT1GSp9OrSAIJxChkL63Wi2isMUIH54SftrOo0MStGdyQ0F/wMee3FbbjLBYLDFlTCEhE4lCkcSVSgXK4SEjZYTZt6cKF/FlZxs7mxtIpddgH/AgRJ5MT6fTwVmH9pERfkhAS3/KxkYWjUYDKml0qSLBMTKMy4EA1tfXkUgkzsTqyioy6TTuPXsCPVUYj8fxc3cXFdLk78UCvFevoJcMKx1sOtT/Ax3wv2EyGGEmQ6+ZmnqAuedzmH06i5nHjzDkHyEbYIONrJ3NZvsHp+tI4fF44HK52GrSmK7nLy0Ym54fgM9DAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Image showing generated ppt presentation before AI generation&quot;
        title=&quot;&quot;
        src=&quot;/static/aa71ae88940b95504537fa76eea64f41/f058b/prez.png&quot;
        srcset=&quot;/static/aa71ae88940b95504537fa76eea64f41/c26ae/prez.png 158w,
/static/aa71ae88940b95504537fa76eea64f41/6bdcf/prez.png 315w,
/static/aa71ae88940b95504537fa76eea64f41/f058b/prez.png 630w,
/static/aa71ae88940b95504537fa76eea64f41/40601/prez.png 945w,
/static/aa71ae88940b95504537fa76eea64f41/78612/prez.png 1260w,
/static/aa71ae88940b95504537fa76eea64f41/09d8d/prez.png 3012w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;
&lt;em&gt;An example generated slide deck on the New Forest&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion: The Future of Presentation Creation&lt;/h2&gt;
&lt;p&gt;Using Claude Desktop with MCPs to generate PowerPoint presentations significantly speeds up the creation process. While the generated output usually requires some manual review and refinement, the automation of research, content structuring, and initial slide population saves considerable effort.&lt;/p&gt;
&lt;p&gt;As you become more familiar with the process, you&apos;ll discover ways to further optimise your prompts and templates, resulting in increasingly polished presentations that require minimal manual adjustment.&lt;/p&gt;
&lt;p&gt;This method provides a practical way to quickly generate presentations that conform to a specific theme, making it useful for various scenarios, from client meetings to internal training.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Your Company is One Resignation Away from AI Disaster]]></title><description><![CDATA[Imagine halving your programme development time with AI only to realise the entire operation hinges on a single motivated employee who could walk out the door tomorrow.]]></description><link>https://quantably.co/ai-paradox/</link><guid isPermaLink="false">https://quantably.co/ai-paradox/</guid><pubDate>Mon, 07 Apr 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Imagine halving your programme development time with AI only to realise the entire operation hinges on a single motivated employee who could walk out the door tomorrow.&lt;/p&gt;
&lt;!-- excerpt --&gt;
&lt;p&gt;One corporate training company I spoke to recently faced exactly this dilemma. Their impressive AI success created an unexpected vulnerability.&lt;/p&gt;
&lt;p&gt;Their AI-secret wasn&apos;t a complex strategy, but a single curious employee who, through trial and error, figured out how to combine LLMs with their deep industry knowledge building well-crafted prompts and applying them throughout their business. AI was used to streamline everything from client discovery, content creation through to quality assurance.&lt;/p&gt;
&lt;p&gt;Sounds great, right?&lt;/p&gt;
&lt;p&gt;But these efficiencies hide a big vulnerability: that their business is one resignation away from AI disaster.&lt;/p&gt;
&lt;p&gt;This isn&apos;t just hypothetical. The problem became clear during one of the team&apos;s post-training analysis calls. The AI expert would usually generate detailed analysis reports right after a training session - giving clients immediate, actionable feedback to discuss during the call. When their AI specialist was unexpectedly absent, there was no one able to step in and generate the reports. The team didn&apos;t understand how to use the tools, leaving them stumbling on the call risking reputation.&lt;/p&gt;
&lt;p&gt;This scenario highlights an emerging risk that many businesses adopting AI face. The tool that gives companies a competitive edge can also represent their biggest vulnerability. While everyone rushes to implement AI faster, sustainable implementation is often overlooked.&lt;/p&gt;
&lt;h2&gt;The Hidden Vulnerability in Your AI Strategy&lt;/h2&gt;
&lt;p&gt;This pattern repeats across industries. For smaller companies and non-tech organisations, where formal AI training programmes don&apos;t exist, success increasingly relies on what we might call &quot;AI pioneers&quot; - those who take initiative to explore and implement AI solutions.&lt;/p&gt;
&lt;p&gt;These pioneers, often through hours of persistence and experimentation, disrupt established workflows often for the better. The systems they build are often brilliant, but their knowledge remains largely undocumented and unshared.&lt;/p&gt;
&lt;p&gt;While AI success stories are celebrated across industries, the vulnerability they create remains largely undiscussed. Consider these increasingly common scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Marketing teams with sophisticated prompt libraries but no documentation of techniques&lt;/li&gt;
&lt;li&gt;Operations departments with streamlined AI workflows known only to their creator&lt;/li&gt;
&lt;li&gt;Customer service systems built on complex LLM knowledge that lives in a single person&apos;s head&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In each case, if the AI pioneer leaves, the team is left scrambling. The competitive edge built on their AI skills disappears overnight. This isn&apos;t just a people problem - it&apos;s a fundamental business risk tied directly to their AI adoption.&lt;/p&gt;
&lt;h2&gt;Building an AI Knowledge Mesh&lt;/h2&gt;
&lt;p&gt;There is a better way.&lt;/p&gt;
&lt;p&gt;AI resilience requires distributing knowledge across the organisation. Rather than concentrating expertise in a few individuals, forward-thinking companies are creating knowledge networks that capture these learnings systematically.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/adf9e15de1efe58f15a1a17212d3b4d7/2bef9/pyramid.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsTAAALEwEAmpwYAAACOElEQVR42sWT2W8SURTG51/zzUSfTGPUFx9MNDFRq9bW1qXGhGhYIpQWiU0LFDAsqTRQW0CmtINKkU2QtrRlhpkBGwoMS4ew43imEK3BNEajJjeTyc35ne87y0UaDPHbB/kXcJ0hann8OLiex/sj+Msc3iwkOZau53+IQY4GNUtkq0zVj/AQ3QKsTDHprXDIBzedEvmFpSHXdxgA7oDaiYeDoXWukgKpHllM7tOb4HnR4Tg3JNyI+Jl0POD3HmR2ge/B4IRjqQeymcvjE11XkA7gajZxQ6AYl6kiwXXnG1fQ//7lvPXEpYc+3zuogodBh6vQ0ciHCyOSgVtCO4pytc+8wzLVLiY1Jssr2xLqXnG4XEqdCX6cKFrOJtolEqkfKrcKxJhMf/L6s1OD0iuC2dLedioR9Xo98I1/Cpitr8XT+kdyldm6iHlWDQu2KY0J8iJd2fDHwJk7kwMjU2fvKk7fnHC6sUpmJ0tuiKb154fF0bBPrjaA4FPl3KTGaLDYnmtNfM3NAsHu7z5WGK4KZgeFajjXnqiGxHMZcpOrpnOpLcyzpjJaFpaWwbZ+3ip6oduOBWAujQKBQJNDIf+wRDsm041K+XNPpr8t0thX1jpFfrbpZOziqMS6bJerjUqt2Ym67ktnwGwtl+AbVs3h/SsFfe71nCH2krFOmXRjq9hbDEqFaYHf3pybxy9mHofGNvJ4p0K3WbrB4DD8n+32oQ6/g318dxe+rcCfvyoc+V/v+e8o478CfwUjLAlzU5/YNgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;pyramid&quot;
        title=&quot;AI Knowledge Pyramid vs Mesh&quot;
        src=&quot;/static/adf9e15de1efe58f15a1a17212d3b4d7/f058b/pyramid.png&quot;
        srcset=&quot;/static/adf9e15de1efe58f15a1a17212d3b4d7/c26ae/pyramid.png 158w,
/static/adf9e15de1efe58f15a1a17212d3b4d7/6bdcf/pyramid.png 315w,
/static/adf9e15de1efe58f15a1a17212d3b4d7/f058b/pyramid.png 630w,
/static/adf9e15de1efe58f15a1a17212d3b4d7/40601/pyramid.png 945w,
/static/adf9e15de1efe58f15a1a17212d3b4d7/2bef9/pyramid.png 1024w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Organisations who successfully distribute their AI knowledge and expertise, experience multiple benefits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Higher overall productivity and efficiency&lt;/li&gt;
&lt;li&gt;Increased talent retention and knowledge preservation&lt;/li&gt;
&lt;li&gt;Greater resilience to disruption&lt;/li&gt;
&lt;li&gt;Reduced operational risks&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This transformation shifts AI knowledge from a pyramid structure (with expertise concentrated in single individuals) into a mesh - where knowledge, including the valuable lessons from trial and error are shared, documented, and accessible to everyone who needs it.&lt;/p&gt;
&lt;h2&gt;Transforming Vulnerability into Strength&lt;/h2&gt;
&lt;p&gt;The following represents a three-step process to transform this AI vulnerability into organisational strength:&lt;/p&gt;
&lt;h3&gt;1. Audit &amp;#x26; Document&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Purpose:&lt;/strong&gt; Create a comprehensive map of your AI operations to understand where knowledge currently resides and capture the experimental journey.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Actions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify and map high-level workflows including current AI touchpoints&lt;/li&gt;
&lt;li&gt;Create a company &quot;AI Playbook&quot; that includes a central library of effective prompts, documenting both successful approaches and failed experiments&lt;/li&gt;
&lt;li&gt;Record video walkthroughs of common AI tasks, including troubleshooting techniques&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Share Knowledge &amp;#x26; Train&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Purpose:&lt;/strong&gt; Transform siloed expertise into collective knowledge through structured learning and practice.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Actions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Organise bi-weekly &quot;AI Skill Share&quot; sessions where pioneers demonstrate their processes&lt;/li&gt;
&lt;li&gt;Establish mentor-mentee pairs for hands-on learning&lt;/li&gt;
&lt;li&gt;Rotate AI responsibilities among team members to build practical experience&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;3. Implement &amp;#x26; Maintain&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Purpose:&lt;/strong&gt; Build resilience into your AI operations through redundancy and contingency planning.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Actions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ensure multiple team members are trained to run each critical AI process&lt;/li&gt;
&lt;li&gt;Develop offline alternatives for critical workflows&lt;/li&gt;
&lt;li&gt;Establish emergency response procedures&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Crucially, this isn&apos;t a one-time checklist but an ongoing cycle. Regularly revisit each phase to adapt to new tools, evolving processes, and changing team knowledge.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Building AI Resilience&lt;/h2&gt;
&lt;p&gt;Having AI initiatives dependent on a few key people is a common challenge. Overcoming this involves addressing key areas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Identifying hidden risks:&lt;/strong&gt; Uncovering where critical AI knowledge gaps and dependencies exist.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Developing a clear roadmap:&lt;/strong&gt; Creating practical plans to distribute expertise and build shared understanding.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Implementing sustainable practices:&lt;/strong&gt; Embedding strategies for documentation, training, and ongoing knowledge sharing.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The key to long-term success with AI is a sustainable implementation. With the right structures in place, businesses can de-risk their AI activities, foster knowledge sharing across teams, and ultimately transform potential vulnerabilities into organisational strength.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Navigating the Shift from Deterministic to Probabilistic Software Engineering]]></title><description><![CDATA[Software engineering is at a crossroads. For decades, the craft has been built on deterministic foundations - where 2+2 always equals 4 and‚Ä¶]]></description><link>https://quantably.co/deterministic-to-probabilistic/</link><guid isPermaLink="false">https://quantably.co/deterministic-to-probabilistic/</guid><pubDate>Sun, 16 Mar 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Software engineering is at a crossroads. For decades, the craft has been built on deterministic foundations - where 2+2 always equals 4 and the same inputs reliably produce the same outputs. But as we advance into the era of AI agents, we&apos;re witnessing a fundamental shift toward probabilistic thinking that&apos;s changing what it means to be a software engineer.&lt;/p&gt;
&lt;h2&gt;The Deterministic vs. Probabilistic Paradigm&lt;/h2&gt;
&lt;p&gt;Traditional software engineering operates in a binary world: good or bad, pass or fail. When 100% of the tests pass, you can ship your product. It&apos;s clean, predictable, and comfortably black and white.&lt;/p&gt;
&lt;p&gt;Probabilistic software, on the other hand, abandons these binary outcomes in favour of statistical efficacy. The questions shift from &quot;Will this work?&quot; to &quot;What&apos;s the likelihood of this working?&quot; This reframing is crucial as we build and deploy increasingly autonomous AI systems.&lt;/p&gt;
&lt;p&gt;This isn&apos;t entirely new territory ‚Äì we&apos;ve had machine learning systems for years. But with the advent of the agentic movement, probabilistic thinking is becoming less of a specialised skill and more of a fundamental requirement.&lt;/p&gt;
&lt;h2&gt;Complexity and Uncertainty&lt;/h2&gt;
&lt;p&gt;As agents become more autonomous their non-deterministic aspects introduce new challenges:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Increased variability in outputs&lt;/li&gt;
&lt;li&gt;Difficulty in comprehensive testing&lt;/li&gt;
&lt;li&gt;Complex security and consistency requirements&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These complexities demand engineers to develop new mental models for designing, testing, and monitoring AI-based solutions.&lt;/p&gt;
&lt;h2&gt;The Reality Behind the Hype: Why Coding Skills Still Matter&lt;/h2&gt;
&lt;p&gt;YouTube is filled with claims that you can &quot;lay off your entire team&quot; or &quot;become a 10x developer&quot; simply by combining tools like Cursor and some MCP servers. While these tools are powerful and impressive, there&apos;s still a substantial gap between flashy proof-of-concept and production-ready system. Not all generated code is correct or useful ‚Äì you need discernment to evaluate it effectively.&lt;/p&gt;
&lt;p&gt;Experienced software engineers understand that coding is just one part of the job. In reality, a substantial part of a senior engineer&apos;s role includes looking at systems holistically, anticipating potential failure points, analysing technical debt, aligning activities with product roadmaps, mentoring team members, and understanding how systems behave at scale.&lt;/p&gt;
&lt;p&gt;These skills become even more critical when dealing with complex, probabilistic AI systems. The value of software engineering isn&apos;t diminishing ‚Äì what&apos;s changing is the additional skillset required to effectively leverage AI tools while still putting systems into production that manage the necessary trade-offs between latency, scale, and reliability.&lt;/p&gt;
&lt;h2&gt;Finding the Right Balance&lt;/h2&gt;
&lt;p&gt;The first question when considering an agent should be: do I actually need one? Not everything requires a probabilistic approach. Sometimes deterministic software is perfectly sufficient ‚Äì and an &quot;agent&quot; could still be running deterministic software under the hood.&lt;/p&gt;
&lt;h2&gt;Adapting to the Agentic Age&lt;/h2&gt;
&lt;p&gt;For engineers who have determined they need to build agent-based systems, several approaches can help navigate the non-deterministic behaviour:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Embrace Structured Outputs&lt;/strong&gt; - The goal isn&apos;t to coerce these models to become deterministic - their probabilistic nature is precisely what makes them powerful. Instead, we need to leverage that strength while building reliable systems. Tools like the Instructor library can be a great starting point in creating controllable structured outputs from LLM models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Self-Validating Systems&lt;/strong&gt; - Increasingly, we&apos;ll use AI systems to verify results from other AI components, creating internal validation loops. See &lt;a href=&quot;https://huggingface.co/learn/cookbook/llm_judge&quot;&gt;LLM-as-a-judge&lt;/a&gt; for a practical example of using language models to evaluate other AI outputs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learn from Existing Systems that Operate Under Uncertainty&lt;/strong&gt; ‚Äì We&apos;re not starting from zero. Reinforcement learning and many machine learning techniques already operate under probabilistic uncertainty. We can and should apply these lessons to agent-based systems. Google&apos;s &lt;a href=&quot;https://storage.googleapis.com/gweb-research2023-media/pubtools/4156.pdf&quot;&gt;ML Test Score&lt;/a&gt; provides a fantastic checklist to assess production-readiness of ML systems.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Focus on the Right Problems and Metrics&lt;/strong&gt; - Understand the problem you&apos;re trying to solve first, not just input/output results or benchmark scores. Ensure your data and metrics accurately represent real-world conditions. Rather than chasing corner cases, evaluate performance across diverse test distributions to build systems that solve the actual problem, not just optimise for artificial metrics.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;The Hybrid Future&lt;/h2&gt;
&lt;p&gt;The future isn&apos;t probabilistic versus deterministic - it&apos;s both. We&apos;ll need all the strengths of traditional software development alongside these new approaches to probabilistic systems.&lt;/p&gt;
&lt;p&gt;The complementary nature of these paradigms will produce the most powerful results as we build increasingly autonomous and capable systems. Great software engineers will be those who can navigate both worlds effectively, understanding when to apply each approach and how to combine them seamlessly.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Building StravaTalk - A Natural Language Interface for Strava Data]]></title><description><![CDATA[In the rapidly evolving world of AI agents, finding the right framework can be challenging. After exploring numerous options that often‚Ä¶]]></description><link>https://quantably.co/conversational-strava/</link><guid isPermaLink="false">https://quantably.co/conversational-strava/</guid><pubDate>Tue, 04 Mar 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;In the rapidly evolving world of AI agents, finding the right framework can be challenging. After exploring numerous options that often added complexity rather than solving problems, I discovered Atomic Agents - a lightweight, flexible framework that perfectly balances sophistication with simplicity. This weekend project lets me analyze years of Strava workout data through natural language questions.&lt;/p&gt;
&lt;h2&gt;The Challenge&lt;/h2&gt;
&lt;p&gt;As a running enthusiast, I&apos;ve accumulated years of workout data in Strava. While the platform offers basic analytics, I wanted the ability to query this treasure trove of information using natural language - asking questions like &quot;What was my longest run last month?&quot; or &quot;Show me my average cycling speed this year&quot; without building complex filters or exports.&lt;/p&gt;
&lt;p&gt;This weekend project is PoC to explore the capabilities of Atomic Agents, but it demonstrates the potential for more sophisticated applications in the future.&lt;/p&gt;
&lt;h2&gt;Enter StravaTalk&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/pwxn/StravaTalk&quot; target=&quot;_blank&quot;&gt;StravaTalk&lt;/a&gt; is a conversational interface that lets me analyse my Strava activities using natural language. Built on the Atomic Agents framework, it transforms English questions into database queries and returns human-friendly responses.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/images/StravaTalk.gif&quot; alt=&quot;StravaTalk App&quot;&gt;&lt;/p&gt;
&lt;h2&gt;How It Works&lt;/h2&gt;
&lt;p&gt;The application follows a straightforward workflow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Preparation&lt;/strong&gt;: First, I used the Strava API to export my historical workout records to a local SQLite database. This one-time setup provides the foundation for all queries.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Query Processing&lt;/strong&gt;: When a user enters a natural language question, it flows through a pipeline of specialised AI agents.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;The Architecture&lt;/h2&gt;
&lt;p&gt;The application uses a multi-agent architecture with three specialised AI components built with Atomic Agents:&lt;/p&gt;
&lt;h3&gt;1. Classification Agent&lt;/h3&gt;
&lt;p&gt;This gatekeeper determines if your query can be answered using available Strava data. It analyses the question, identifies what data would be required, and classifies it as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SQL-appropriate (can be answered with available data)&lt;/li&gt;
&lt;li&gt;Not SQL-appropriate (requires data we don&apos;t have)&lt;/li&gt;
&lt;li&gt;Clarification needed (ambiguous query)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. SQL Agent&lt;/h3&gt;
&lt;p&gt;For questions that can be answered, this agent converts natural language into optimised SQL queries. It understands the database schema (activities, segments, etc.) and builds queries that accurately represent the user&apos;s intent.&lt;/p&gt;
&lt;h3&gt;3. Response Agent&lt;/h3&gt;
&lt;p&gt;This agent transforms raw database results into human-friendly responses. It formats data with appropriate units (converting metres to kilometres, formatting pace correctly), and presents information in an engaging, motivational way.&lt;/p&gt;
&lt;h2&gt;Shared Memory&lt;/h2&gt;
&lt;p&gt;One of the most powerful features is the shared memory implementation. All agents access the same conversation context, enabling follow-up questions like &quot;How does that compare to last year?&quot; without repeating context.&lt;/p&gt;
&lt;h2&gt;Structured Outputs&lt;/h2&gt;
&lt;p&gt;Thanks to Atomic Agents&apos; integration with &lt;a href=&quot;https://github.com/jxnl/instructor&quot;&gt;Instructor&lt;/a&gt;, the entire system works with strongly typed outputs. This reduces hallucinations and ensures data consistency across the pipeline.&lt;/p&gt;
&lt;h2&gt;The Development Experience&lt;/h2&gt;
&lt;p&gt;What impressed me most about building with Atomic Agents was how quickly I could go from concept to working prototype. The framework strikes an excellent balance between:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Production-ready features (robust error handling, performance optimisation)&lt;/li&gt;
&lt;li&gt;Developer experience (clean, readable code)&lt;/li&gt;
&lt;li&gt;Flexibility (easy to customise and extend)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I completed the initial version in a single weekend, something that would have taken weeks with many other frameworks.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;StravaTalk demonstrates how modern AI frameworks can transform personal data into conversational insights. While this project focuses on Strava data, the architecture could be applied to any structured dataset. Thanks to frameworks like Atomic Agents, building sophisticated AI applications is becoming increasingly accessible to developers, opening up new possibilities for natural, conversation-driven interfaces.&lt;/p&gt;</content:encoded></item></channel></rss>